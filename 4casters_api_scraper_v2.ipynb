{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import config\n",
    "\n",
    "#Function to grab the auth token\n",
    "def grab_auth_token():\n",
    "\n",
    "    #First we need to login to the API to get the auth token\n",
    "    login_url = \"https://api.4casters.io/user/login\"\n",
    "    payload = {\n",
    "        \"username\": config.USERNAME,\n",
    "        \"password\": config.PASSWORD \n",
    "    }\n",
    "    headers = {}\n",
    "    response = requests.request(\"POST\", login_url, headers=headers, data=payload)\n",
    "\n",
    "    #Save Auth token as a variable\n",
    "    auth_token = response.json()['data']['user']['auth']\n",
    "    return auth_token\n",
    "#Function to grab the raw orderbook\n",
    "def scrape_raw_orderbook(auth_token):\n",
    "    url = \"https://api.4casters.io/exchange/v2/getOrderbook?league=nba\"\n",
    "\n",
    "    payload = \"\"\n",
    "    headers = {\n",
    "        'Authorization':auth_token\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    game_data = response.json()\n",
    "    game_data = game_data['data']['games']\n",
    "\n",
    "    # Extract game details\n",
    "    games_list = []\n",
    "    for game in game_data:\n",
    "        games_list.append({\n",
    "            \"Game ID\": game[\"id\"],\n",
    "            \"Matchup\": f\"{game['participants'][0]['longName']} vs {game['participants'][1]['longName']}\",\n",
    "            \"Start Time\": game[\"start\"],\n",
    "            \"League\": game[\"league\"],\n",
    "        })\n",
    "    return game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_token = grab_auth_token()\n",
    "game_data = scrape_raw_orderbook(auth_token)\n",
    "print(game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these helper functions at the top of your file\n",
    "\n",
    "def calculate_best_odds(odds_series):\n",
    "    \"\"\"\n",
    "    Find best odds considering American odds format.\n",
    "    For negative odds, less negative is better (-110 is better than -120)\n",
    "    For positive odds, higher is better (+120 is better than +110)\n",
    "    \"\"\"\n",
    "    if odds_series.empty:\n",
    "        return None\n",
    "    if all(odds_series < 0):\n",
    "        return odds_series.max()  # Least negative\n",
    "    elif all(odds_series > 0):\n",
    "        return odds_series.max()  # Highest positive\n",
    "    else:\n",
    "        # Mixed positive and negative odds - find best in each category\n",
    "        neg_best = odds_series[odds_series < 0].max() if any(odds_series < 0) else None\n",
    "        pos_best = odds_series[odds_series > 0].max() if any(odds_series > 0) else None\n",
    "        \n",
    "        # Return the overall best (challenging to compare +/- directly)\n",
    "        if neg_best is None:\n",
    "            return pos_best\n",
    "        if pos_best is None:\n",
    "            return neg_best\n",
    "        # If both exist, return the one with better implied probability\n",
    "        # (would require conversion to decimal odds for true comparison)\n",
    "        return pos_best  # Simplified; typically positive odds offer better value\n",
    "        \n",
    "def get_odds_range(odds_series):\n",
    "    \"\"\"\n",
    "    Returns the range of odds [best, worst] respecting American odds format\n",
    "    Best odds come first, worst odds second\n",
    "    \"\"\"\n",
    "    if odds_series.empty:\n",
    "        return [None, None]\n",
    "        \n",
    "    if all(odds_series < 0):\n",
    "        # For negative odds, best is least negative, worst is most negative\n",
    "        return [odds_series.max(), odds_series.min()]\n",
    "    elif all(odds_series > 0):\n",
    "        # For positive odds, best is highest, worst is lowest\n",
    "        return [odds_series.max(), odds_series.min()]\n",
    "    else:\n",
    "        # Mixed positive and negative - need to determine which is best\n",
    "        # Typically positive odds are better than negative odds\n",
    "        pos_odds = odds_series[odds_series > 0]\n",
    "        neg_odds = odds_series[odds_series < 0]\n",
    "        \n",
    "        if not pos_odds.empty and not neg_odds.empty:\n",
    "            # If we have both, determine which is better based on implied probability\n",
    "            return [pos_odds.max(), neg_odds.min()]\n",
    "        elif not pos_odds.empty:\n",
    "            return [pos_odds.max(), pos_odds.min()]\n",
    "        else:\n",
    "            return [neg_odds.max(), neg_odds.min()]\n",
    "        \n",
    "\n",
    "# Add this new function at the top of your file, alongside your other helper functions\n",
    "def get_odds_list(odds_series):\n",
    "    \"\"\"\n",
    "    Returns a sorted list of all distinct odds, from most competitive to least competitive\n",
    "    \"\"\"\n",
    "    if odds_series.empty:\n",
    "        return []\n",
    "        \n",
    "    if all(odds_series < 0):\n",
    "        # For negative odds, sort from least negative to most negative\n",
    "        return sorted(odds_series.unique(), reverse=True)\n",
    "    elif all(odds_series > 0):\n",
    "        # For positive odds, sort from highest to lowest\n",
    "        return sorted(odds_series.unique(), reverse=True)\n",
    "    else:\n",
    "        # Mixed positive and negative - sort each separately then combine\n",
    "        pos_odds = sorted(odds_series[odds_series > 0].unique(), reverse=True)\n",
    "        neg_odds = sorted(odds_series[odds_series < 0].unique(), reverse=True)\n",
    "        \n",
    "        # Return positive odds first (typically better value), then negative odds\n",
    "        return pos_odds + neg_odds\n",
    "    \n",
    "def get_top_competitive_odds(odds_series, top_n=6):\n",
    "    \"\"\"\n",
    "    Returns the top N most competitive distinct odds, regardless of liquidity\n",
    "    \"\"\"\n",
    "    if odds_series.empty:\n",
    "        return []\n",
    "        \n",
    "    if all(odds_series < 0):\n",
    "        # For negative odds, get least negative (best) first\n",
    "        return sorted(odds_series.unique(), reverse=True)[:top_n]\n",
    "    elif all(odds_series > 0):\n",
    "        # For positive odds, get highest (best) first\n",
    "        return sorted(odds_series.unique(), reverse=True)[:top_n]\n",
    "    else:\n",
    "        # Mixed positive and negative\n",
    "        pos_odds = sorted(odds_series[odds_series > 0].unique(), reverse=True)\n",
    "        neg_odds = sorted(odds_series[odds_series < 0].unique(), reverse=True)\n",
    "        \n",
    "        # Combine and take top N\n",
    "        combined = pos_odds + neg_odds\n",
    "        return combined[:top_n]\n",
    "\n",
    " \n",
    "def calculate_imbalance(numerator, denominator, default_value=0):\n",
    "    \"\"\"\n",
    "    Calculate ratio between two values with proper handling of zero denominator\n",
    "    \"\"\"\n",
    "    if denominator > 0:\n",
    "        return numerator / denominator\n",
    "    return default_value  # Instead of infinity, use a default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to verify there isn't some sort of error or issue with collection of orderbook data \n",
    "def check_analysis_consistency(ml_analysis, spread_analysis):\n",
    "    \"\"\"Check for consistency between moneyline and spread analyses\"\"\"\n",
    "    \n",
    "    # Skip check if either analysis lacks sufficient data\n",
    "    if not ml_analysis['has_significant_data'] or not spread_analysis['has_significant_data']:\n",
    "        return {\n",
    "            'consistent': None,\n",
    "            'reason': \"Insufficient data for consistency check\",\n",
    "            'details': {}\n",
    "        }\n",
    "    \n",
    "    # Compare favorite/underdog designations\n",
    "    ml_favorite = ml_analysis['favorite_team']\n",
    "    spread_favorite = spread_analysis['favorite_team']\n",
    "    \n",
    "    if ml_favorite == spread_favorite:\n",
    "        return {\n",
    "            'consistent': True,\n",
    "            'reason': \"Consistent favorite across markets\",\n",
    "            'details': {\n",
    "                'favorite': ml_favorite\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'consistent': False,\n",
    "            'reason': \"Inconsistent favorite designations\",\n",
    "            'details': {\n",
    "                'moneyline_favorite': ml_favorite,\n",
    "                'spread_favorite': spread_favorite,\n",
    "                'moneyline_favorite_odds': ml_analysis['favorite_best_odds'],\n",
    "                'spread_favorite_odds': spread_analysis['favorite_odds_range']\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_matched_liquidity(df, threshold=50):\n",
    "    \"\"\"Identify matched liquidity between opposite sides of the same market, processing each game separately\"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Initialize the matched liquidity column\n",
    "    df_copy['matched_liquidity'] = False\n",
    "    \n",
    "    # Process each game separately\n",
    "    for game_id in df_copy['GameID'].unique():\n",
    "        game_df = df_copy[df_copy['GameID'] == game_id]\n",
    "        \n",
    "        # Process spread markets\n",
    "        spread_df = game_df[game_df['Market'] == 'Spread']\n",
    "        \n",
    "        # Group by spread value\n",
    "        spreads = spread_df['Spread/Total'].unique()\n",
    "        \n",
    "        for spread_value in spreads:\n",
    "            if pd.isna(spread_value) or spread_value == \"N/A\":\n",
    "                continue\n",
    "                \n",
    "            # Get opposite spread\n",
    "            opposite_spread = -1 * float(spread_value)\n",
    "            \n",
    "            # Get bets on both sides of this spread\n",
    "            current_spread = spread_df[abs(spread_df['Spread/Total'] - float(spread_value)) < 0.5]\n",
    "            opposite_spread_df = spread_df[abs(spread_df['Spread/Total'] - opposite_spread) < 0.5]\n",
    "            \n",
    "            # Skip if either side is empty\n",
    "            if current_spread.empty or opposite_spread_df.empty:\n",
    "                continue\n",
    "            \n",
    "            # Check for matching bet amounts within threshold\n",
    "            for idx1, current_row in current_spread.iterrows():\n",
    "                for idx2, opposite_row in opposite_spread_df.iterrows():\n",
    "                    if abs(current_row['Bet Amount'] - opposite_row['Bet Amount']) <= threshold:\n",
    "                        # Mark both rows as matched liquidity\n",
    "                        df_copy.loc[idx1, 'matched_liquidity'] = True\n",
    "                        df_copy.loc[idx2, 'matched_liquidity'] = True\n",
    "\n",
    "    \n",
    "        \n",
    "        #Process moneyline markets \n",
    "        ml_df = game_df[game_df['Market'] == 'Moneyline']\n",
    "\n",
    "        if not ml_df.empty:\n",
    "\n",
    "            away_ml = ml_df[ml_df['Side'] == 'Away']\n",
    "            home_ml = ml_df[ml_df['Side'] == 'Home']\n",
    "            # We need to determine favorite and underdog based on odds - that will tell us which column to use for comparison\n",
    "            if not away_ml.empty and not home_ml.empty:\n",
    "                # Calculate average odds for each side\n",
    "                away_avg_odds = away_ml['Odds'].mean()\n",
    "                home_avg_odds = home_ml['Odds'].mean()\n",
    "                \n",
    "                #negative odds = favorite, positive odds = underdog\n",
    "                if away_avg_odds < 0 and home_avg_odds > 0:\n",
    "                    # Away is favorite, Home is underdog\n",
    "                    favorite_ml = away_ml\n",
    "                    underdog_ml = home_ml\n",
    "                else:\n",
    "                    # Home is favorite, Away is underdog\n",
    "                    favorite_ml = home_ml\n",
    "                    underdog_ml = away_ml\n",
    "                \n",
    "                # Check for matching values: Compare favorite's Bet Amount with underdog's Sum Untaken\n",
    "                for idx_fav, fav_row in favorite_ml.iterrows():\n",
    "                    for idx_dog, dog_row in underdog_ml.iterrows():\n",
    "                        if abs(fav_row['Bet Amount'] - dog_row['Sum Untaken']) <= threshold:\n",
    "                            # Mark both rows as matched liquidity\n",
    "                            df_copy.loc[idx_fav, 'matched_liquidity'] = True\n",
    "                            df_copy.loc[idx_dog, 'matched_liquidity'] = True\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_moneyline(ml_df):\n",
    "    \"\"\"\n",
    "    Analyze moneyline orderbook data - focus on correct classification and filtering\n",
    "    \"\"\"\n",
    "    # Create empty summary in case of empty dataframe\n",
    "    if ml_df.empty:\n",
    "        return {\n",
    "            'favorite_side': None,\n",
    "            'underdog_side': None,\n",
    "            'favorite_team': None,\n",
    "            'underdog_team': None,\n",
    "            'favorite_best_odds': None,\n",
    "            'underdog_best_odds': None,\n",
    "            'underdog_untaken_sum': 0,\n",
    "            'favorite_bet_amount': 0,\n",
    "            'imbalance': 0,\n",
    "            'has_significant_data': False\n",
    "        }\n",
    "    \n",
    "    # Add matched liquidity identification\n",
    "    ml_df_with_matches = identify_matched_liquidity(ml_df)\n",
    "    # Use non-matched liquidity for sharp signal detection\n",
    "    ml_df_sharp = ml_df_with_matches[~ml_df_with_matches['matched_liquidity']]\n",
    "    matched_percentage = (ml_df_with_matches['matched_liquidity'].sum() / len(ml_df_with_matches)) * 100 if not ml_df_with_matches.empty else 0\n",
    "    \n",
    "    # Split by side\n",
    "    away_ml = ml_df[ml_df['Side'] == 'Away']\n",
    "    home_ml = ml_df[ml_df['Side'] == 'Home']\n",
    "    \n",
    "    # Get team names if available\n",
    "    away_team = away_ml['Team'].iloc[0] if not away_ml.empty else \"Away\"\n",
    "    home_team = home_ml['Team'].iloc[0] if not home_ml.empty else \"Home\"\n",
    "    \n",
    "    # Determine favorite and underdog based on average odds\n",
    "    away_avg_odds = away_ml['Odds'].mean() if not away_ml.empty else 0\n",
    "    home_avg_odds = home_ml['Odds'].mean() if not home_ml.empty else 0\n",
    "    \n",
    "    if away_avg_odds < 0 and home_avg_odds > 0:\n",
    "        # Away is favorite, Home is underdog\n",
    "        favorite_side = 'Away'\n",
    "        underdog_side = 'Home'\n",
    "        favorite_team = away_team\n",
    "        underdog_team = home_team\n",
    "        favorite = away_ml\n",
    "        underdog = home_ml\n",
    "    else:\n",
    "        # Home is favorite (default), Away is underdog\n",
    "        favorite_side = 'Home'\n",
    "        underdog_side = 'Away'\n",
    "        favorite_team = home_team\n",
    "        underdog_team = away_team\n",
    "        favorite = home_ml\n",
    "        underdog = away_ml\n",
    "    \n",
    "    # Filter out insignificant wagers\n",
    "    favorite_sig = favorite[favorite['Bet Amount'] >= 100]\n",
    "    underdog_sig = underdog[underdog['Sum Untaken'] >= 100]\n",
    "    \n",
    "    has_significant_data = not favorite_sig.empty and not underdog_sig.empty\n",
    "    \n",
    "        # Find best odds using helper function\n",
    "    favorite_best_odds = calculate_best_odds(favorite_sig['Odds']) if not favorite_sig.empty else None\n",
    "    underdog_best_odds = calculate_best_odds(underdog_sig['Odds']) if not underdog_sig.empty else None\n",
    "    \n",
    "    # To this new approach:\n",
    "    favorite_filtered = pd.DataFrame()\n",
    "    underdog_filtered = pd.DataFrame()\n",
    "\n",
    "    if not favorite_sig.empty:\n",
    "        # Sort by odds competitiveness\n",
    "        if all(favorite_sig['Odds'] < 0):\n",
    "            # For negative odds, sort from least negative to most negative\n",
    "            sorted_favorite = favorite_sig.sort_values('Odds', ascending=False)\n",
    "        else:\n",
    "            # For positive odds, sort from highest to lowest\n",
    "            sorted_favorite = favorite_sig.sort_values('Odds', ascending=False)\n",
    "        \n",
    "        # Get up to 5 unique price points (might be fewer)\n",
    "        unique_prices = sorted_favorite['Odds'].drop_duplicates().head(5)\n",
    "        favorite_filtered = sorted_favorite[sorted_favorite['Odds'].isin(unique_prices)]\n",
    "\n",
    "    if not underdog_sig.empty:\n",
    "        # Sort by odds competitiveness\n",
    "        if all(underdog_sig['Odds'] > 0):\n",
    "            # For positive odds, sort from highest to lowest\n",
    "            sorted_underdog = underdog_sig.sort_values('Odds', ascending=False)\n",
    "        else:\n",
    "            # For negative odds, sort from least negative to most negative\n",
    "            sorted_underdog = underdog_sig.sort_values('Odds', ascending=False)\n",
    "        \n",
    "        # Get up to 5 unique price points\n",
    "        unique_prices = sorted_underdog['Odds'].drop_duplicates().head(5)\n",
    "        underdog_filtered = sorted_underdog[sorted_underdog['Odds'].isin(unique_prices)]\n",
    "    # Calculate metrics for the filtered data\n",
    "    underdog_untaken_sum = underdog_filtered['Sum Untaken'].sum() if not underdog_filtered.empty else 0\n",
    "    favorite_bet_amount = favorite_filtered['Bet Amount'].sum() if not favorite_filtered.empty else 0\n",
    "    imbalance = calculate_imbalance(underdog_untaken_sum, favorite_bet_amount)\n",
    "    \n",
    "    # Summary with all information but no signals\n",
    "    summary = {\n",
    "        'favorite_side': favorite_side,\n",
    "        'underdog_side': underdog_side,\n",
    "        'favorite_team': favorite_team,\n",
    "        'underdog_team': underdog_team,\n",
    "        'favorite_best_odds': favorite_best_odds,\n",
    "        'underdog_best_odds': underdog_best_odds,\n",
    "        'underdog_untaken_sum': underdog_untaken_sum,\n",
    "        'favorite_bet_amount': favorite_bet_amount,\n",
    "        'imbalance': imbalance,\n",
    "        'has_significant_data': has_significant_data,\n",
    "        'favorite_filtered_count': len(favorite_filtered) if not favorite_filtered.empty else 0,\n",
    "        'underdog_filtered_count': len(underdog_filtered) if not underdog_filtered.empty else 0\n",
    "    }\n",
    "    \n",
    "    # After filtering, add odds ranges and liquidity sums - CORRECTED\n",
    "    if has_significant_data:\n",
    "        # Add odds ranges with correct ordering\n",
    "        if not favorite_filtered.empty:\n",
    "            # Add odds ranges using helper function\n",
    "            summary['favorite_filtered_odds_range'] = get_odds_range(favorite_filtered['Odds']) if not favorite_filtered.empty else [None, None]\n",
    "            # Add complete odds list (new)\n",
    "            summary['favorite_filtered_odds_list'] = get_odds_list(favorite_filtered['Odds']) if not favorite_filtered.empty else []\n",
    "                        \n",
    "        if not underdog_filtered.empty:\n",
    "            # Add odds ranges using helper function\n",
    "            summary['underdog_filtered_odds_range'] = get_odds_range(underdog_filtered['Odds']) if not underdog_filtered.empty else [None, None]\n",
    "            # Add complete odds list (new)\n",
    "            summary['underdog_filtered_odds_list'] = get_odds_list(underdog_filtered['Odds']) if not underdog_filtered.empty else []\n",
    "\n",
    "        summary['favorite_raw_odds_list'] = get_top_competitive_odds(favorite_sig['Odds'], top_n=6) if not favorite_sig.empty else []\n",
    "        summary['underdog_raw_odds_list'] = get_top_competitive_odds(underdog_sig['Odds'], top_n=6) if not underdog_sig.empty else []\n",
    "\n",
    "    \n",
    "        # Add complete liquidity information (kept separate)\n",
    "        summary['favorite_untaken_sum'] = favorite_filtered['Sum Untaken'].sum() if not favorite_filtered.empty else 0\n",
    "        summary['underdog_bet_amount'] = underdog_filtered['Bet Amount'].sum() if not underdog_filtered.empty else 0\n",
    "        \n",
    "        # Add the other side liquidity measures (not used for imbalance but informative)\n",
    "        summary['favorite_all_untaken_sum'] = favorite_sig['Sum Untaken'].sum() if not favorite_sig.empty else 0\n",
    "        summary['favorite_all_bet_amount'] = favorite_sig['Bet Amount'].sum() if not favorite_sig.empty else 0\n",
    "        summary['underdog_all_untaken_sum'] = underdog_sig['Sum Untaken'].sum() if not underdog_sig.empty else 0\n",
    "        summary['underdog_all_bet_amount'] = underdog_sig['Bet Amount'].sum() if not underdog_sig.empty else 0\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def process_spread(spread_df):\n",
    "    \"\"\"\n",
    "    Analyze spread orderbook data - focus on correct classification and filtering\n",
    "    \"\"\"\n",
    "    # Create empty summary in case of empty dataframe\n",
    "    if spread_df.empty:\n",
    "        return {\n",
    "            'main_spread': None,\n",
    "            'away_main_spread': None,\n",
    "            'home_main_spread': None,\n",
    "            'favorite_side': None,\n",
    "            'underdog_side': None,\n",
    "            'favorite_team': None,\n",
    "            'underdog_team': None,\n",
    "            'has_significant_data': False\n",
    "        }\n",
    "    \n",
    "    # Convert spread to numeric if not already\n",
    "    spread_df['Spread/Total'] = pd.to_numeric(spread_df['Spread/Total'], errors='coerce')\n",
    "    \n",
    "    # Split by side\n",
    "    away_spread = spread_df[spread_df['Side'] == 'Away']\n",
    "    home_spread = spread_df[spread_df['Side'] == 'Home']\n",
    "    \n",
    "    # Get team names if available\n",
    "    away_team = away_spread['Team'].iloc[0] if not away_spread.empty else \"Away\"\n",
    "    home_team = home_spread['Team'].iloc[0] if not home_spread.empty else \"Home\"\n",
    "    \n",
    "    # Filter out small wagers\n",
    "    away_spread_sig = away_spread[away_spread['Sum Untaken'] + away_spread['Bet Amount'] >= 100]\n",
    "    home_spread_sig = home_spread[home_spread['Sum Untaken'] + home_spread['Bet Amount'] >= 100]\n",
    "    \n",
    "    has_significant_data = not away_spread_sig.empty and not home_spread_sig.empty\n",
    "    \n",
    "    #Counts how many bets are at each spread value, the spread with the most is the \"main spread\"\n",
    "    #We don't want to count the amt of open interest because sometimes there is massive open interest at unreasonably prices\n",
    "    away_spread_counts = away_spread_sig.groupby('Spread/Total').size() if not away_spread_sig.empty else pd.Series()\n",
    "    away_main_spread = away_spread_counts.idxmax() if not away_spread_counts.empty else None\n",
    "    \n",
    "    home_spread_counts = home_spread_sig.groupby('Spread/Total').size() if not home_spread_sig.empty else pd.Series()\n",
    "    home_main_spread = home_spread_counts.idxmax() if not home_spread_counts.empty else None\n",
    "    \n",
    "    #Initialize empty dataframes\n",
    "    # Replace with this new filtering approach:\n",
    "    away_main_filtered = pd.DataFrame()\n",
    "    home_main_filtered = pd.DataFrame()\n",
    "\n",
    "    if not away_spread_sig.empty and away_main_spread is not None:\n",
    "        # Get only the away bets at the main spread\n",
    "        away_main_bets = away_spread_sig[away_spread_sig['Spread/Total'] == away_main_spread]\n",
    "        \n",
    "        if not away_main_bets.empty:\n",
    "            # Sort by odds competitiveness\n",
    "            if all(away_main_bets['Odds'] < 0):\n",
    "                # For negative odds, sort from least negative to most negative\n",
    "                sorted_away = away_main_bets.sort_values('Odds', ascending=False)\n",
    "            else:\n",
    "                # For positive odds, sort from highest to lowest\n",
    "                sorted_away = away_main_bets.sort_values('Odds', ascending=False)\n",
    "            \n",
    "            # Get up to 5 unique price points\n",
    "            unique_prices = sorted_away['Odds'].drop_duplicates().head(5)\n",
    "            away_main_filtered = sorted_away[sorted_away['Odds'].isin(unique_prices)]\n",
    "\n",
    "    if not home_spread_sig.empty and home_main_spread is not None:\n",
    "        # Get only the home bets at the main spread\n",
    "        home_main_bets = home_spread_sig[home_spread_sig['Spread/Total'] == home_main_spread]\n",
    "        \n",
    "        if not home_main_bets.empty:\n",
    "            # Sort by odds competitiveness\n",
    "            if all(home_main_bets['Odds'] < 0):\n",
    "                # For negative odds, sort from least negative to most negative\n",
    "                sorted_home = home_main_bets.sort_values('Odds', ascending=False)\n",
    "            else:\n",
    "                # For positive odds, sort from highest to lowest\n",
    "                sorted_home = home_main_bets.sort_values('Odds', ascending=False)\n",
    "            \n",
    "            # Get up to 5 unique price points\n",
    "            unique_prices = sorted_home['Odds'].drop_duplicates().head(5)\n",
    "            home_main_filtered = sorted_home[sorted_home['Odds'].isin(unique_prices)]\n",
    "    \n",
    "    # Determine overall main spread\n",
    "    main_spread = None\n",
    "    \n",
    "    if away_main_spread is not None and home_main_spread is not None:\n",
    "        # Check if they're close to being opposites (allowing for small differences)\n",
    "        if abs(abs(away_main_spread) - abs(home_main_spread)) < 1:\n",
    "            # They're approximately opposites, use the one with more activity\n",
    "            if away_spread_counts.get(away_main_spread, 0) > home_spread_counts.get(home_main_spread, 0):\n",
    "                main_spread = away_main_spread\n",
    "            else:\n",
    "                main_spread = home_main_spread\n",
    "        else:\n",
    "            # They're not opposites - use the one with more activity\n",
    "            if away_spread_counts.get(away_main_spread, 0) > home_spread_counts.get(home_main_spread, 0):\n",
    "                main_spread = away_main_spread\n",
    "            else:\n",
    "                main_spread = home_main_spread\n",
    "    elif away_main_spread is not None:\n",
    "        main_spread = away_main_spread\n",
    "    elif home_main_spread is not None:\n",
    "        main_spread = home_main_spread\n",
    "    \n",
    "    # Get all bets at the main spread line, accounting for signs\n",
    "    if main_spread is not None:\n",
    "        away_main_bets = away_spread[abs(abs(away_spread['Spread/Total']) - abs(main_spread)) < 0.5]\n",
    "        home_main_bets = home_spread[abs(abs(home_spread['Spread/Total']) - abs(main_spread)) < 0.5]\n",
    "        main_spread_df = pd.concat([away_main_bets, home_main_bets])\n",
    "    else:\n",
    "        away_main_bets = pd.DataFrame()\n",
    "        home_main_bets = pd.DataFrame()\n",
    "        main_spread_df = pd.DataFrame()\n",
    "\n",
    "    # Now use away_main_bets and home_main_bets directly\n",
    "    away_main = away_main_bets\n",
    "    home_main = home_main_bets\n",
    "    #Don't use the odds number, we need the actual handicap number to determine the side that is favorite/dog\n",
    "    away_handicap = away_main['Spread/Total'].median() if not away_main.empty else 0\n",
    "    home_handicap = home_main['Spread/Total'].median() if not home_main.empty else 0\n",
    "    print(away_handicap, home_handicap)\n",
    "    \n",
    "    if away_handicap < 0 and home_handicap > 0:\n",
    "        # Away is favorite, Home is underdog\n",
    "        favorite_side = 'Away'\n",
    "        underdog_side = 'Home'\n",
    "        favorite_team = away_team\n",
    "        underdog_team = home_team\n",
    "        favorite_spread = away_main_filtered\n",
    "        underdog_spread = home_main_filtered\n",
    "    else:\n",
    "        # Home is favorite, Away is underdog\n",
    "        favorite_side = 'Home'\n",
    "        underdog_side = 'Away'\n",
    "        favorite_team = home_team\n",
    "        underdog_team = away_team\n",
    "        favorite_spread = home_main_filtered\n",
    "        underdog_spread = away_main_filtered\n",
    "    \n",
    "    # Calculate metrics\n",
    "    underdog_untaken = underdog_spread['Sum Untaken'].sum() if not underdog_spread.empty else 0\n",
    "    favorite_bet = favorite_spread['Bet Amount'].sum() if not favorite_spread.empty else 0\n",
    "    imbalance = calculate_imbalance(underdog_untaken, favorite_bet, default_value=float('inf'))\n",
    "    \n",
    "    # Summary without signals\n",
    "    summary = {\n",
    "        'main_spread': main_spread,\n",
    "        'away_main_spread': away_main_spread,\n",
    "        'home_main_spread': home_main_spread,\n",
    "        'favorite_side': favorite_side,\n",
    "        'underdog_side': underdog_side,\n",
    "        'favorite_team': favorite_team,\n",
    "        'underdog_team': underdog_team,\n",
    "        'underdog_untaken': underdog_untaken,\n",
    "        'favorite_bet': favorite_bet,\n",
    "        'imbalance': imbalance,\n",
    "        'has_significant_data': has_significant_data\n",
    "    }\n",
    "    \n",
    "    # Add details for debugging - CORRECTED odds ranges\n",
    "    if has_significant_data:\n",
    "        # Add odds ranges with correct ordering\n",
    "        if not favorite_spread.empty:\n",
    "            # Add odds ranges using helper function\n",
    "            summary['favorite_filtered_odds_range'] = get_odds_range(favorite_spread['Odds']) if not favorite_spread.empty else [None, None]\n",
    "            # Add complete odds list (new)\n",
    "            summary['favorite_filtered_odds_list'] = get_odds_list(favorite_spread['Odds']) if not favorite_spread.empty else []\n",
    "                        \n",
    "        if not underdog_spread.empty:\n",
    "            # Add odds ranges using helper function\n",
    "            summary['underdog_filtered_odds_range'] = get_odds_range(underdog_spread['Odds']) if not underdog_spread.empty else [None, None]\n",
    "            # Add complete odds list (new)\n",
    "            summary['underdog_filtered_odds_list'] = get_odds_list(underdog_spread['Odds']) if not underdog_spread.empty else []\n",
    "            # Add raw odds info (new) - using away_main_bets and home_main_bets (before filtering)\n",
    "        if not away_main_bets.empty and favorite_side == 'Away':\n",
    "            summary['favorite_raw_odds_list'] = get_top_competitive_odds(away_main_bets['Odds'], top_n=6)\n",
    "        elif not home_main_bets.empty and favorite_side == 'Home':\n",
    "            summary['favorite_raw_odds_list'] = get_top_competitive_odds(home_main_bets['Odds'], top_n=6)\n",
    "        else:\n",
    "            summary['favorite_raw_odds_list'] = []\n",
    "            \n",
    "        if not home_main_bets.empty and underdog_side == 'Home':\n",
    "            summary['underdog_raw_odds_list'] = get_top_competitive_odds(home_main_bets['Odds'], top_n=6)\n",
    "        elif not away_main_bets.empty and underdog_side == 'Away':\n",
    "            summary['underdog_raw_odds_list'] = get_top_competitive_odds(away_main_bets['Odds'], top_n=6)\n",
    "        else:\n",
    "            summary['underdog_raw_odds_list'] = []\n",
    "\n",
    "            \n",
    "        # For the filtered data at main spread\n",
    "        summary['favorite_untaken'] = favorite_spread['Sum Untaken'].sum() if not favorite_spread.empty else 0\n",
    "        summary['favorite_bet'] = favorite_spread['Bet Amount'].sum() if not favorite_spread.empty else 0\n",
    "        summary['underdog_untaken'] = underdog_spread['Sum Untaken'].sum() if not underdog_spread.empty else 0\n",
    "        summary['underdog_bet'] = underdog_spread['Bet Amount'].sum() if not underdog_spread.empty else 0\n",
    "        \n",
    "        # For all significant data\n",
    "        if not away_spread_sig.empty and not home_spread_sig.empty:\n",
    "            if favorite_side == 'Away':\n",
    "                summary['favorite_all_untaken'] = away_spread_sig['Sum Untaken'].sum()\n",
    "                summary['favorite_all_bet'] = away_spread_sig['Bet Amount'].sum()\n",
    "                summary['underdog_all_untaken'] = home_spread_sig['Sum Untaken'].sum()\n",
    "                summary['underdog_all_bet'] = home_spread_sig['Bet Amount'].sum()\n",
    "            else:\n",
    "                summary['favorite_all_untaken'] = home_spread_sig['Sum Untaken'].sum()\n",
    "                summary['favorite_all_bet'] = home_spread_sig['Bet Amount'].sum()\n",
    "                summary['underdog_all_untaken'] = away_spread_sig['Sum Untaken'].sum()\n",
    "                summary['underdog_all_bet'] = away_spread_sig['Bet Amount'].sum()\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sharp_signals(ml_analysis, spread_analysis):\n",
    "    \"\"\"Detect sharp signals based on moneyline and spread analysis\"\"\"\n",
    "    signals = []\n",
    "    \n",
    "    # Moneyline signals\n",
    "    if ml_analysis['has_significant_data']:\n",
    "        if ml_analysis['imbalance'] > 1.5 and ml_analysis['underdog_untaken_sum'] > 1500:\n",
    "            signals.append({\n",
    "                'market': 'Moneyline',\n",
    "                'signal': ml_analysis['favorite_team'],\n",
    "                'strength': 'Strong' if ml_analysis['imbalance'] > 5 else 'Moderate',\n",
    "                'reason': f\"Large untaken amount on {ml_analysis['underdog_team']} (${ml_analysis['underdog_untaken_sum']:.2f})\"\n",
    "            })\n",
    "        elif ml_analysis['imbalance'] < 0.5 and ml_analysis['favorite_bet_amount'] > 1500:\n",
    "            signals.append({\n",
    "                'market': 'Moneyline',\n",
    "                'signal': ml_analysis['underdog_team'],\n",
    "                'strength': 'Strong' if ml_analysis['imbalance'] < 0.2 else 'Moderate',\n",
    "                'reason': f\"Large bet amount on {ml_analysis['favorite_team']} (${ml_analysis['favorite_bet_amount']:.2f})\"\n",
    "            })\n",
    "    \n",
    "    # Spread signals\n",
    "    if spread_analysis['has_significant_data'] and spread_analysis['main_spread'] is not None:\n",
    "        if spread_analysis['imbalance'] > 1.5 and spread_analysis['underdog_untaken'] > 1500:\n",
    "            signals.append({\n",
    "                'market': 'Spread',\n",
    "                'signal': spread_analysis['favorite_team'],\n",
    "                'line': spread_analysis['main_spread'],\n",
    "                'strength': 'Strong' if spread_analysis['imbalance'] > 5 else 'Moderate',\n",
    "                'reason': f\"Large untaken amount on {spread_analysis['underdog_team']} (${spread_analysis['underdog_untaken']:.2f})\"\n",
    "            })\n",
    "        elif spread_analysis['imbalance'] < 0.5 and spread_analysis['favorite_bet'] > 1500:\n",
    "            signals.append({\n",
    "                'market': 'Spread',\n",
    "                'signal': spread_analysis['underdog_team'],\n",
    "                'line': spread_analysis['main_spread'],\n",
    "                'strength': 'Strong' if spread_analysis['imbalance'] < 0.2 else 'Moderate',\n",
    "                'reason': f\"Large bet amount on {spread_analysis['favorite_team']} (${spread_analysis['favorite_bet']:.2f})\"\n",
    "            })\n",
    "    \n",
    "    return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_unmatched_liquidity(game_data, game_df):\n",
    "    \"\"\"\n",
    "    Identify significant unmatched liquidity at competitive prices\n",
    "    \n",
    "    Parameters:\n",
    "    game_data (dict): Parsed game data containing moneyline and spread information\n",
    "    game_df (DataFrame): Raw game data with matched_liquidity column\n",
    "    \n",
    "    Returns:\n",
    "    dict: Analysis of unmatched liquidity with significance ratings\n",
    "    \"\"\"\n",
    "    ml_data = game_data['moneyline']\n",
    "    spread_data = game_data['spread']\n",
    "    results = {\n",
    "        'moneyline_signals': [],\n",
    "        'spread_signals': [],\n",
    "        'total_signals': 0\n",
    "    }\n",
    "    \n",
    "    # Get only unmatched liquidity rows\n",
    "    unmatched_df = game_df[game_df['matched_liquidity'] == False]\n",
    "    \n",
    "    # Analyze moneyline unmatched liquidity\n",
    "    if ml_data['has_significant_data']:\n",
    "        # Split by market and side\n",
    "        ml_unmatched = unmatched_df[unmatched_df['Market'] == 'Moneyline']\n",
    "        fav_unmatched = ml_unmatched[ml_unmatched['Side'] == ml_data['favorite_side']]\n",
    "        dog_unmatched = ml_unmatched[ml_unmatched['Side'] == ml_data['underdog_side']]\n",
    "        \n",
    "        # Check favorite side\n",
    "        fav_raw_odds = ml_data.get('favorite_raw_odds_list', [])\n",
    "        \n",
    "        if fav_raw_odds and len(fav_raw_odds) > 0:\n",
    "            # Consider top 6 competitive prices\n",
    "            top_n = min(6, len(fav_raw_odds))\n",
    "            competitive_prices = fav_raw_odds[:top_n]\n",
    "            \n",
    "            # Filter unmatched liquidity to only include these competitive prices\n",
    "            #Use bet amount instead of sum untaken for favorites, we want high amts of to win, not risk\n",
    "            fav_competitive_unmatched = fav_unmatched[fav_unmatched['Odds'].isin(competitive_prices)]\n",
    "            fav_bet_amount = fav_competitive_unmatched['Bet Amount'].sum() if not fav_competitive_unmatched.empty else 0\n",
    "            \n",
    "            if fav_bet_amount > 1000:\n",
    "                # Create detailed breakdown by price point\n",
    "                price_breakdown = []\n",
    "                for price in competitive_prices:\n",
    "                    price_rows = fav_unmatched[fav_unmatched['Odds'] == price]\n",
    "                    price_sum = price_rows['Bet Amount'].sum() if not price_rows.empty else 0\n",
    "                    if price_sum > 0:\n",
    "                        price_breakdown.append({\n",
    "                            'price': price,\n",
    "                            'amount': price_sum\n",
    "                        })\n",
    "                \n",
    "                results['moneyline_signals'].append({\n",
    "                    'side': 'Favorite',\n",
    "                    'team': ml_data['favorite_team'],\n",
    "                    'untaken_amount': fav_bet_amount,\n",
    "                    'competitive_prices': competitive_prices,\n",
    "                    'price_breakdown': price_breakdown,\n",
    "                    'significance': 'High' if fav_bet_amount > 1000 else 'Medium'\n",
    "                })\n",
    "        \n",
    "        # Check underdog side with same approach\n",
    "        dog_raw_odds = ml_data.get('underdog_raw_odds_list', [])\n",
    "        \n",
    "        if dog_raw_odds and len(dog_raw_odds) > 0:\n",
    "            top_n = min(6, len(dog_raw_odds))\n",
    "            competitive_prices = dog_raw_odds[:top_n]\n",
    "            \n",
    "            dog_competitive_unmatched = dog_unmatched[dog_unmatched['Odds'].isin(competitive_prices)]\n",
    "            dog_untaken_sum = dog_competitive_unmatched['Sum Untaken'].sum() if not dog_competitive_unmatched.empty else 0\n",
    "            \n",
    "            if dog_untaken_sum > 1000:\n",
    "                price_breakdown = []\n",
    "                for price in competitive_prices:\n",
    "                    price_rows = dog_unmatched[dog_unmatched['Odds'] == price]\n",
    "                    price_sum = price_rows['Sum Untaken'].sum() if not price_rows.empty else 0\n",
    "                    if price_sum > 0:\n",
    "                        price_breakdown.append({\n",
    "                            'price': price,\n",
    "                            'amount': price_sum\n",
    "                        })\n",
    "                \n",
    "                results['moneyline_signals'].append({\n",
    "                    'side': 'Underdog',\n",
    "                    'team': ml_data['underdog_team'],\n",
    "                    'untaken_amount': dog_untaken_sum,\n",
    "                    'competitive_prices': competitive_prices,\n",
    "                    'price_breakdown': price_breakdown,\n",
    "                    'significance': 'High' if dog_untaken_sum > 1000 else 'Medium'\n",
    "                })\n",
    "    \n",
    "    # Analyze spread unmatched liquidity with the same approach\n",
    "    if spread_data['has_significant_data'] and spread_data.get('main_spread') is not None:\n",
    "        # Split by market and side\n",
    "        spread_unmatched = unmatched_df[unmatched_df['Market'] == 'Spread']\n",
    "        \n",
    "        # Only get spreads at the main spread line\n",
    "        main_spread = spread_data.get('main_spread')\n",
    "        spread_unmatched = spread_unmatched[abs(abs(spread_unmatched['Spread/Total']) - abs(main_spread)) < 0.5]\n",
    "        \n",
    "        fav_unmatched = spread_unmatched[spread_unmatched['Side'] == spread_data['favorite_side']]\n",
    "        dog_unmatched = spread_unmatched[spread_unmatched['Side'] == spread_data['underdog_side']]\n",
    "        \n",
    "        # Favorite side\n",
    "        fav_raw_odds = spread_data.get('favorite_raw_odds_list', [])\n",
    "        \n",
    "        if fav_raw_odds and len(fav_raw_odds) > 0:\n",
    "            top_n = min(6, len(fav_raw_odds))\n",
    "            competitive_prices = fav_raw_odds[:top_n]\n",
    "            \n",
    "            fav_competitive_unmatched = fav_unmatched[fav_unmatched['Odds'].isin(competitive_prices)]\n",
    "            fav_untaken_sum = fav_competitive_unmatched['Sum Untaken'].sum() if not fav_competitive_unmatched.empty else 0\n",
    "            \n",
    "            if fav_untaken_sum > 1000:\n",
    "                price_breakdown = []\n",
    "                for price in competitive_prices:\n",
    "                    price_rows = fav_unmatched[fav_unmatched['Odds'] == price]\n",
    "                    price_sum = price_rows['Sum Untaken'].sum() if not price_rows.empty else 0\n",
    "                    if price_sum > 0:\n",
    "                        price_breakdown.append({\n",
    "                            'price': price,\n",
    "                            'amount': price_sum\n",
    "                        })\n",
    "                \n",
    "                results['spread_signals'].append({\n",
    "                    'side': 'Favorite',\n",
    "                    'team': spread_data['favorite_team'],\n",
    "                    'spread': main_spread,\n",
    "                    'untaken_amount': fav_untaken_sum,\n",
    "                    'competitive_prices': competitive_prices,\n",
    "                    'price_breakdown': price_breakdown,\n",
    "                    'significance': 'High' if fav_untaken_sum > 1000 else 'Medium'\n",
    "                })\n",
    "        \n",
    "        # Underdog side\n",
    "        dog_raw_odds = spread_data.get('underdog_raw_odds_list', [])\n",
    "        \n",
    "        if dog_raw_odds and len(dog_raw_odds) > 0:\n",
    "            top_n = min(6, len(dog_raw_odds))\n",
    "            competitive_prices = dog_raw_odds[:top_n]\n",
    "            \n",
    "            dog_competitive_unmatched = dog_unmatched[dog_unmatched['Odds'].isin(competitive_prices)]\n",
    "            dog_untaken_sum = dog_competitive_unmatched['Sum Untaken'].sum() if not dog_competitive_unmatched.empty else 0\n",
    "            \n",
    "            if dog_untaken_sum > 1000:\n",
    "                price_breakdown = []\n",
    "                for price in competitive_prices:\n",
    "                    price_rows = dog_unmatched[dog_unmatched['Odds'] == price]\n",
    "                    price_sum = price_rows['Sum Untaken'].sum() if not price_rows.empty else 0\n",
    "                    if price_sum > 0:\n",
    "                        price_breakdown.append({\n",
    "                            'price': price,\n",
    "                            'amount': price_sum\n",
    "                        })\n",
    "                \n",
    "                results['spread_signals'].append({\n",
    "                    'side': 'Underdog',\n",
    "                    'team': spread_data['underdog_team'],\n",
    "                    'spread': main_spread,\n",
    "                    'untaken_amount': dog_untaken_sum,\n",
    "                    'competitive_prices': competitive_prices,\n",
    "                    'price_breakdown': price_breakdown,\n",
    "                    'significance': 'High' if dog_untaken_sum > 1000 else 'Medium'\n",
    "                })\n",
    "    \n",
    "    # Calculate total signals\n",
    "    results['total_signals'] = len(results['moneyline_signals']) + len(results['spread_signals'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_top_book_imbalance(game_data, game_df):\n",
    "    \"\"\"\n",
    "    Detect significant imbalances at the top of the orderbook between corresponding sides\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'moneyline_signals': [],\n",
    "        'spread_signals': [],\n",
    "        'total_signals': 0,\n",
    "        'moneyline_summary': {\n",
    "            'has_data': False,\n",
    "            'favorite_top_volume': 0,\n",
    "            'favorite_breakdown': [],\n",
    "            'underdog_top_volume': 0,\n",
    "            'underdog_breakdown': []\n",
    "        },\n",
    "        'spread_summary': {\n",
    "            'has_data': False,\n",
    "            'favorite_top_volume': 0,\n",
    "            'favorite_breakdown': [],\n",
    "            'underdog_top_volume': 0,\n",
    "            'underdog_breakdown': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Analyze spread market\n",
    "    spread_data = game_data['spread']\n",
    "    \n",
    "    if spread_data['has_significant_data'] and spread_data.get('main_spread') is not None:\n",
    "        # Create a filtered dataframe just for spread market\n",
    "        spread_df = game_df[game_df['Market'] == 'Spread'].copy()\n",
    "        \n",
    "        # Get favorite and underdog data\n",
    "        fav_df = spread_df[spread_df['Side'] == spread_data['favorite_side']]\n",
    "        dog_df = spread_df[spread_df['Side'] == spread_data['underdog_side']]\n",
    "        \n",
    "        # Get the top prices from each side\n",
    "        fav_raw_odds = spread_data.get('favorite_raw_odds_list', [])\n",
    "        dog_raw_odds = spread_data.get('underdog_raw_odds_list', [])\n",
    "        \n",
    "        if fav_raw_odds and dog_raw_odds and not fav_df.empty and not dog_df.empty:\n",
    "            # Use top 3 price levels (or fewer if not available)\n",
    "            top_n = min(3, len(fav_raw_odds), len(dog_raw_odds))\n",
    "            \n",
    "            # Calculate volume for top N price levels for favorite\n",
    "            fav_top_volume = 0\n",
    "            fav_top_breakdown = []\n",
    "            \n",
    "            for i in range(top_n):\n",
    "                if i < len(fav_raw_odds):\n",
    "                    price = fav_raw_odds[i]\n",
    "                    # Get all bets at this price\n",
    "                    price_bets = fav_df[fav_df['Odds'] == price]\n",
    "                    \n",
    "                    #Sum of bet amount\n",
    "                    price_volume = price_bets['Bet Amount'].sum()\n",
    "                    fav_top_volume += price_volume\n",
    "                    \n",
    "                    fav_top_breakdown.append({\n",
    "                        'price': price,\n",
    "                        'volume': price_volume\n",
    "                    })\n",
    "            \n",
    "            # Calculate volume for top N price levels for underdog\n",
    "            dog_top_volume = 0\n",
    "            dog_top_breakdown = []\n",
    "            \n",
    "            for i in range(top_n):\n",
    "                if i < len(dog_raw_odds):\n",
    "                    price = dog_raw_odds[i]\n",
    "                    # Get all bets at this price\n",
    "                    price_bets = dog_df[dog_df['Odds'] == price]\n",
    "                    \n",
    "                    # Sum of bet amount \n",
    "                    price_volume = price_bets['Bet Amount'].sum()\n",
    "                    dog_top_volume += price_volume\n",
    "                    \n",
    "                    dog_top_breakdown.append({\n",
    "                        'price': price,\n",
    "                        'volume': price_volume\n",
    "                    })\n",
    "                       # Store summary data regardless of imbalance\n",
    "            results['spread_summary'] = {\n",
    "                'has_data': True,\n",
    "                'main_spread': spread_data['main_spread'],\n",
    "                'favorite_team': spread_data['favorite_team'],\n",
    "                'underdog_team': spread_data['underdog_team'],\n",
    "                'favorite_top_volume': fav_top_volume,\n",
    "                'favorite_breakdown': fav_top_breakdown,\n",
    "                'underdog_top_volume': dog_top_volume,\n",
    "                'underdog_breakdown': dog_top_breakdown\n",
    "            }\n",
    "            # Calculate imbalance ratio - larger side divided by smaller side\n",
    "            if fav_top_volume > dog_top_volume and dog_top_volume > 0:\n",
    "                larger_side = 'Favorite'\n",
    "                larger_team = spread_data['favorite_team']\n",
    "                smaller_team = spread_data['underdog_team']\n",
    "                ratio = fav_top_volume / dog_top_volume\n",
    "            elif dog_top_volume > fav_top_volume and fav_top_volume > 0:\n",
    "                larger_side = 'Underdog'\n",
    "                larger_team = spread_data['underdog_team']\n",
    "                smaller_team = spread_data['favorite_team']\n",
    "                ratio = dog_top_volume / fav_top_volume\n",
    "            else:\n",
    "                # Equal or one is zero\n",
    "                larger_side = None\n",
    "                ratio = 0\n",
    "            \n",
    "            # Signal if there's a significant imbalance AND the larger side has meaningful volume\n",
    "            min_volume_threshold = 1000\n",
    "            ratio_threshold = 1.5\n",
    "            \n",
    "            if larger_side and ratio > ratio_threshold and (fav_top_volume > min_volume_threshold or dog_top_volume > min_volume_threshold):\n",
    "                results['spread_signals'].append({\n",
    "                    'market': 'Spread',\n",
    "                    'signal': smaller_team, #The side that has the most open interest is the side that the SHARP bettors are betting against, so the smaller team is the signal\n",
    "                    'larger_side': larger_side,\n",
    "                    'main_spread': spread_data['main_spread'],\n",
    "                    'favorite_top_volume': fav_top_volume,\n",
    "                    'favorite_breakdown': fav_top_breakdown,\n",
    "                    'underdog_top_volume': dog_top_volume,\n",
    "                    'underdog_breakdown': dog_top_breakdown,\n",
    "                    'imbalance_ratio': ratio,\n",
    "                    'significance': 'High' if ratio > 7 else 'Medium'\n",
    "                })\n",
    "    \n",
    "    # Analyze moneyline market (no Spread/Total issue here)\n",
    "    ml_data = game_data['moneyline']\n",
    "    \n",
    "    if ml_data['has_significant_data']:\n",
    "        # Get the top prices from each side\n",
    "        fav_raw_odds = ml_data.get('favorite_raw_odds_list', [])\n",
    "        dog_raw_odds = ml_data.get('underdog_raw_odds_list', [])\n",
    "        \n",
    "        if fav_raw_odds and dog_raw_odds:\n",
    "            # Use top 3 price levels (or fewer if not available)\n",
    "            top_n = min(3, len(fav_raw_odds), len(dog_raw_odds))\n",
    "            \n",
    "            # Calculate volume for top N price levels for favorite\n",
    "            fav_top_volume = 0\n",
    "            fav_top_breakdown = []\n",
    "            \n",
    "            for i in range(top_n):\n",
    "                price = fav_raw_odds[i]\n",
    "                price_bets = game_df[(game_df['Market'] == 'Moneyline') & \n",
    "                                   (game_df['Side'] == ml_data['favorite_side']) &\n",
    "                                   (game_df['Odds'] == price)]\n",
    "                #Use bet amount for fav(to win amount)\n",
    "                price_volume = price_bets['Bet Amount'].sum()\n",
    "                fav_top_volume += price_volume\n",
    "                \n",
    "                fav_top_breakdown.append({\n",
    "                    'price': price,\n",
    "                    'volume': price_volume\n",
    "                })\n",
    "            \n",
    "            # Calculate volume for top N price levels for underdog\n",
    "            dog_top_volume = 0\n",
    "            dog_top_breakdown = []\n",
    "            \n",
    "            for i in range(top_n):\n",
    "                price = dog_raw_odds[i]\n",
    "                price_bets = game_df[(game_df['Market'] == 'Moneyline') & \n",
    "                                   (game_df['Side'] == ml_data['underdog_side']) &\n",
    "                                   (game_df['Odds'] == price)]\n",
    "                #Use sum untaken for dog(risk amount)\n",
    "                price_volume = price_bets['Sum Untaken'].sum()\n",
    "                dog_top_volume += price_volume\n",
    "                \n",
    "                dog_top_breakdown.append({\n",
    "                    'price': price,\n",
    "                    'volume': price_volume\n",
    "                })\n",
    "                        # Store summary data regardless of imbalance\n",
    "            results['moneyline_summary'] = {\n",
    "                'has_data': True,\n",
    "                'favorite_team': ml_data['favorite_team'],\n",
    "                'underdog_team': ml_data['underdog_team'],\n",
    "                'favorite_top_volume': fav_top_volume,\n",
    "                'favorite_breakdown': fav_top_breakdown,\n",
    "                'underdog_top_volume': dog_top_volume,\n",
    "                'underdog_breakdown': dog_top_breakdown\n",
    "            }\n",
    "            # Calculate imbalance ratio\n",
    "            if fav_top_volume > dog_top_volume:\n",
    "                larger_side = 'Favorite'\n",
    "                larger_team = ml_data['favorite_team']\n",
    "                smaller_team = ml_data['underdog_team']\n",
    "                ratio = fav_top_volume / dog_top_volume if dog_top_volume > 0 else float('inf')\n",
    "            else:\n",
    "                larger_side = 'Underdog'\n",
    "                larger_team = ml_data['underdog_team']\n",
    "                smaller_team = ml_data['favorite_team']\n",
    "                ratio = dog_top_volume / fav_top_volume if fav_top_volume > 0 else float('inf')\n",
    "            \n",
    "            # Moneyline markets often have more natural imbalance, so use higher threshold\n",
    "            min_volume_threshold = 500\n",
    "            ratio_threshold = 1.5  # Higher for moneyline than spread\n",
    "            \n",
    "            if ratio > ratio_threshold and (fav_top_volume > min_volume_threshold or dog_top_volume > min_volume_threshold):\n",
    "                results['moneyline_signals'].append({\n",
    "                    'market': 'Moneyline',\n",
    "                    'signal': smaller_team, #The side that has the most open interest is the side that the SHARP bettors are betting against, so the smaller team is the signal\n",
    "                    'larger_side': larger_side,\n",
    "                    'favorite_top_volume': fav_top_volume,\n",
    "                    'favorite_breakdown': fav_top_breakdown,\n",
    "                    'underdog_top_volume': dog_top_volume,\n",
    "                    'underdog_breakdown': dog_top_breakdown,\n",
    "                    'imbalance_ratio': ratio,\n",
    "                    'significance': 'High' if ratio > 8 else 'Medium'\n",
    "                })\n",
    "    \n",
    "    # Calculate total signals\n",
    "    results['total_signals'] = len(results['moneyline_signals']) + len(results['spread_signals'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich.layout import Layout\n",
    "from rich.text import Text\n",
    "from rich.box import ROUNDED\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "console = Console()\n",
    "\n",
    "def create_dashboard(analyses):\n",
    "    \"\"\"Create a rich dashboard layout with comprehensive orderbook analysis data\"\"\"\n",
    "    # Create layout\n",
    "    layout = Layout()\n",
    "    layout.split(\n",
    "        Layout(name=\"header\", size=3),\n",
    "        Layout(name=\"main\")\n",
    "    )\n",
    "    layout[\"main\"].split_row(\n",
    "        Layout(name=\"signals\", ratio=2),\n",
    "        Layout(name=\"details\", ratio=2)\n",
    "    )\n",
    "    \n",
    "    # Create header\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    header = Panel(f\"Orderbook Analysis Dashboard - Last Updated: {current_time}\", style=\"bold blue\")\n",
    "    layout[\"header\"].update(header)\n",
    "    \n",
    "    # Create signals table\n",
    "    signals_table = Table(title=\"Detected Signals\", box=ROUNDED)\n",
    "    signals_table.add_column(\"Game\", style=\"cyan\", no_wrap=True)\n",
    "    signals_table.add_column(\"Signal\", style=\"green\")\n",
    "    signals_table.add_column(\"Market\", style=\"magenta\")\n",
    "    signals_table.add_column(\"Strength\", style=\"yellow\")\n",
    "    signals_table.add_column(\"Ratio\", style=\"red\")\n",
    "    \n",
    "    # Add rows for each signal\n",
    "    signal_count = 0\n",
    "    for game_id, analysis in analyses.items():\n",
    "        game_name = f\"{analysis['game_info']['away_team']} @ {analysis['game_info']['home_team']}\"\n",
    "        \n",
    "        # Add sharp signals\n",
    "        for signal in analysis.get('sharp_signals', []):\n",
    "            signals_table.add_row(\n",
    "                game_name,\n",
    "                signal['signal'],\n",
    "                signal['market'],\n",
    "                signal['strength'],\n",
    "                \"N/A\"\n",
    "            )\n",
    "            signal_count += 1\n",
    "        \n",
    "        # Add top book imbalances\n",
    "        if 'top_book_imbalance' in analysis:\n",
    "            for signal in analysis['top_book_imbalance'].get('moneyline_signals', []):\n",
    "                signals_table.add_row(\n",
    "                    game_name,\n",
    "                    signal['signal'],\n",
    "                    \"ML Imbalance\",\n",
    "                    signal['significance'],\n",
    "                    f\"{signal['imbalance_ratio']:.2f}x\"\n",
    "                )\n",
    "                signal_count += 1\n",
    "            \n",
    "            for signal in analysis['top_book_imbalance'].get('spread_signals', []):\n",
    "                signals_table.add_row(\n",
    "                    game_name,\n",
    "                    signal['signal'],\n",
    "                    f\"Spread {signal.get('main_spread', '')}\",\n",
    "                    signal['significance'],\n",
    "                    f\"{signal['imbalance_ratio']:.2f}x\"\n",
    "                )\n",
    "                signal_count += 1\n",
    "        \n",
    "        # Add unmatched liquidity signals\n",
    "        if 'unmatched_liquidity' in analysis:\n",
    "            for signal in analysis['unmatched_liquidity'].get('moneyline_signals', []):\n",
    "                signals_table.add_row(\n",
    "                    game_name,\n",
    "                    signal.get('signal', 'Unknown'),\n",
    "                    \"ML Unmatched\",\n",
    "                    signal.get('significance', 'Unknown'),\n",
    "                    \"N/A\"\n",
    "                )\n",
    "                signal_count += 1\n",
    "            \n",
    "            for signal in analysis['unmatched_liquidity'].get('spread_signals', []):\n",
    "                signals_table.add_row(\n",
    "                    game_name,\n",
    "                    signal.get('signal', 'Unknown'),\n",
    "                    f\"Spread {signal.get('spread', '')} Unmatched\",\n",
    "                    signal.get('significance', 'Unknown'),\n",
    "                    \"N/A\"\n",
    "                )\n",
    "                signal_count += 1\n",
    "    if signal_count == 0:\n",
    "        signals_table.add_row(\"No signals detected\", \"\", \"\", \"\", \"\")\n",
    "    \n",
    "    # Create details table with raw orderbook data\n",
    "    details = Table(title=\"Orderbook Details\", box=ROUNDED)\n",
    "    details.add_column(\"Game\", style=\"cyan\", no_wrap=True)\n",
    "    details.add_column(\"Market\", style=\"yellow\")\n",
    "    details.add_column(\"Teams\", style=\"green\")\n",
    "    details.add_column(\"Top Prices\", style=\"magenta\")\n",
    "    details.add_column(\"Volume by Team\", style=\"blue\", justify=\"right\")\n",
    "    \n",
    "    for game_id, analysis in analyses.items():\n",
    "        game_name = f\"{analysis['game_info']['away_team']} @ {analysis['game_info']['home_team']}\"\n",
    "        \n",
    "        # Add moneyline details\n",
    "        ml_data = analysis.get('moneyline', {})\n",
    "        if ml_data and 'favorite_team' in ml_data:\n",
    "            fav_team = ml_data['favorite_team']\n",
    "            dog_team = ml_data['underdog_team']\n",
    "            \n",
    "            # Get top book summary if available\n",
    "            if 'top_book_imbalance' in analysis and analysis['top_book_imbalance']['moneyline_summary']['has_data']:\n",
    "                ml_summary = analysis['top_book_imbalance']['moneyline_summary']\n",
    "                \n",
    "                # Format top prices\n",
    "                fav_prices = []\n",
    "                for price in ml_summary['favorite_breakdown'][:3]:\n",
    "                    fav_prices.append(f\"{price['price']}:{price['volume']:.0f}\")\n",
    "                \n",
    "                dog_prices = []\n",
    "                for price in ml_summary['underdog_breakdown'][:3]:\n",
    "                    dog_prices.append(f\"{price['price']}:{price['volume']:.0f}\")\n",
    "                \n",
    "                fav_prices_str = \", \".join(fav_prices)\n",
    "                dog_prices_str = \", \".join(dog_prices)\n",
    "                \n",
    "                prices_display = f\"{fav_team}: {fav_prices_str}\\n{dog_team}: {dog_prices_str}\"\n",
    "                \n",
    "                # Format volumes with team names\n",
    "                volumes_display = f\"{fav_team}: ${ml_summary['favorite_top_volume']:.0f}\\n{dog_team}: ${ml_summary['underdog_top_volume']:.0f}\"\n",
    "                \n",
    "                details.add_row(\n",
    "                    game_name,\n",
    "                    \"Moneyline\",\n",
    "                    f\"{fav_team} (Fav) vs\\n{dog_team} (Dog)\",\n",
    "                    prices_display,\n",
    "                    volumes_display\n",
    "                )\n",
    "        \n",
    "        # Add spread details\n",
    "        spread_data = analysis.get('spread', {})\n",
    "        if spread_data and 'favorite_team' in spread_data:\n",
    "            fav_team = spread_data['favorite_team']\n",
    "            dog_team = spread_data['underdog_team']\n",
    "            \n",
    "            # Get top book summary if available\n",
    "            if 'top_book_imbalance' in analysis and analysis['top_book_imbalance']['spread_summary']['has_data']:\n",
    "                spread_summary = analysis['top_book_imbalance']['spread_summary']\n",
    "                \n",
    "                # Format top prices\n",
    "                fav_prices = []\n",
    "                for price in spread_summary['favorite_breakdown'][:3]:\n",
    "                    fav_prices.append(f\"{price['price']}:{price['volume']:.0f}\")\n",
    "                \n",
    "                dog_prices = []\n",
    "                for price in spread_summary['underdog_breakdown'][:3]:\n",
    "                    dog_prices.append(f\"{price['price']}:{price['volume']:.0f}\")\n",
    "                \n",
    "                fav_prices_str = \", \".join(fav_prices)\n",
    "                dog_prices_str = \", \".join(dog_prices)\n",
    "                \n",
    "                prices_display = f\"{fav_team}: {fav_prices_str}\\n{dog_team}: {dog_prices_str}\"\n",
    "                \n",
    "                # Format volumes with team names\n",
    "                volumes_display = f\"{fav_team}: ${spread_summary['favorite_top_volume']:.0f}\\n{dog_team}: ${spread_summary['underdog_top_volume']:.0f}\"\n",
    "                \n",
    "                details.add_row(\n",
    "                    game_name,\n",
    "                    f\"Spread {spread_data.get('main_spread', '')}\",\n",
    "                    f\"{fav_team} (Fav) vs\\n{dog_team} (Dog)\",\n",
    "                    prices_display,\n",
    "                    volumes_display\n",
    "                )\n",
    "    \n",
    "    # Update the layout\n",
    "    layout[\"signals\"].update(signals_table)\n",
    "    layout[\"details\"].update(details)\n",
    "    \n",
    "    return layout\n",
    "\n",
    "def display_dashboard(analyses):\n",
    "    \"\"\"Display the dashboard once\"\"\"\n",
    "    dashboard = create_dashboard(analyses)\n",
    "    console.print(dashboard)\n",
    "\n",
    "def live_dashboard(analyze_func, interval_seconds=300):\n",
    "    \"\"\"Run a live updating dashboard\"\"\"\n",
    "    with console.screen() as screen:\n",
    "        while True:\n",
    "            try:\n",
    "                # Run analysis\n",
    "                analyses, _ = analyze_func()\n",
    "                \n",
    "                # Update dashboard\n",
    "                dashboard = create_dashboard(analyses)\n",
    "                screen.update(dashboard)\n",
    "                \n",
    "                # Wait for next update\n",
    "                time.sleep(interval_seconds)\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                console.print(f\"[bold red]Error: {str(e)}[/bold red]\")\n",
    "                time.sleep(30)  # Wait a bit before retrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def process_full_orderbook(orderbook_data):\n",
    "    \"\"\"Process the full orderbook data for all games at once\"\"\"\n",
    "    all_games_bet_data = []\n",
    "    all_games_info = {}\n",
    "    \n",
    "    # Iterate through each game in the response\n",
    "    for game in orderbook_data:\n",
    "        game_id = game['id']\n",
    "        event_name = game['eventName']\n",
    "        \n",
    "        # Extract team information\n",
    "        home_team = next((p['shortName'] for p in game['participants'] if p['homeAway'] == 'home'), None)\n",
    "        away_team = next((p['shortName'] for p in game['participants'] if p['homeAway'] == 'away'), None)\n",
    "        \n",
    "        # Store game info\n",
    "        all_games_info[game_id] = {\n",
    "            \"event_name\": event_name,\n",
    "            \"league\": game['league'],\n",
    "            \"start_time\": game['start'],\n",
    "            \"home_team\": home_team,\n",
    "            \"away_team\": away_team\n",
    "        }\n",
    "        \n",
    "        # Process moneylines\n",
    "        for bet in game.get('awayMoneylines', []):\n",
    "            all_games_bet_data.append({\n",
    "                \"GameID\": game_id,\n",
    "                \"Event\": event_name,\n",
    "                \"Market\": \"Moneyline\",\n",
    "                \"Side\": \"Away\",\n",
    "                \"Team\": away_team,\n",
    "                \"Odds\": bet[\"odds\"],\n",
    "                \"Spread/Total\": \"N/A\",\n",
    "                \"Sum Untaken\": bet[\"sumUntaken\"],\n",
    "                \"Bet Amount\": bet[\"bet\"]\n",
    "            })\n",
    "            \n",
    "        for bet in game.get('homeMoneylines', []):\n",
    "            all_games_bet_data.append({\n",
    "                \"GameID\": game_id,\n",
    "                \"Event\": event_name,\n",
    "                \"Market\": \"Moneyline\",\n",
    "                \"Side\": \"Home\",\n",
    "                \"Team\": home_team,\n",
    "                \"Odds\": bet[\"odds\"],\n",
    "                \"Spread/Total\": \"N/A\",\n",
    "                \"Sum Untaken\": bet[\"sumUntaken\"],\n",
    "                \"Bet Amount\": bet[\"bet\"]\n",
    "            })\n",
    "        \n",
    "        # Process spreads - these are in list format in your JSON\n",
    "        for bet in game.get('awaySpreads', []):\n",
    "            all_games_bet_data.append({\n",
    "                \"GameID\": game_id,\n",
    "                \"Event\": event_name,\n",
    "                \"Market\": \"Spread\",\n",
    "                \"Side\": \"Away\",\n",
    "                \"Team\": away_team,\n",
    "                \"Odds\": bet[\"odds\"],\n",
    "                \"Spread/Total\": bet[\"spread\"],\n",
    "                \"Sum Untaken\": bet[\"sumUntaken\"],\n",
    "                \"Bet Amount\": bet[\"bet\"]\n",
    "            })\n",
    "                \n",
    "        for bet in game.get('homeSpreads', []):\n",
    "            all_games_bet_data.append({\n",
    "                \"GameID\": game_id,\n",
    "                \"Event\": event_name, \n",
    "                \"Market\": \"Spread\",\n",
    "                \"Side\": \"Home\",\n",
    "                \"Team\": home_team,\n",
    "                \"Odds\": bet[\"odds\"],\n",
    "                \"Spread/Total\": bet[\"spread\"],\n",
    "                \"Sum Untaken\": bet[\"sumUntaken\"],\n",
    "                \"Bet Amount\": bet[\"bet\"]\n",
    "            })\n",
    "        \n",
    "        # Process totals\n",
    "        for bet in game.get('over', []):\n",
    "            all_games_bet_data.append({\n",
    "                \"GameID\": game_id,\n",
    "                \"Event\": event_name,\n",
    "                \"Market\": \"Total\",\n",
    "                \"Side\": \"Over\",\n",
    "                \"Team\": \"N/A\",\n",
    "                \"Odds\": bet[\"odds\"],\n",
    "                \"Spread/Total\": bet[\"total\"],\n",
    "                \"Sum Untaken\": bet[\"sumUntaken\"],\n",
    "                \"Bet Amount\": bet[\"bet\"]\n",
    "            })\n",
    "            \n",
    "        for bet in game.get('under', []):\n",
    "            all_games_bet_data.append({\n",
    "                \"GameID\": game_id,\n",
    "                \"Event\": event_name,\n",
    "                \"Market\": \"Total\",\n",
    "                \"Side\": \"Under\", \n",
    "                \"Team\": \"N/A\",\n",
    "                \"Odds\": bet[\"odds\"],\n",
    "                \"Spread/Total\": bet[\"total\"],\n",
    "                \"Sum Untaken\": bet[\"sumUntaken\"],\n",
    "                \"Bet Amount\": bet[\"bet\"]\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_games_bet_data)\n",
    "    return df, all_games_info\n",
    "\n",
    "def analyze_all_games(orderbook_data):\n",
    "    \"\"\"Analyze all games in the orderbook and detect sharp signals\"\"\"\n",
    "    # Process the full orderbook\n",
    "    all_games_df, all_games_info = process_full_orderbook(orderbook_data)\n",
    "    \n",
    "    # Add a column for matched liquidity to the full dataset\n",
    "    all_games_df['matched_liquidity'] = False\n",
    "\n",
    "    #For each game, identify matched liquidity for each bet type\n",
    "    for game_id in all_games_df['GameID'].unique():\n",
    "        game_df = all_games_df[all_games_df['GameID'] == game_id]\n",
    "        matched_liquidity = identify_matched_liquidity(game_df, threshold=50)\n",
    "        all_games_df.loc[all_games_df['GameID'] == game_id, 'matched_liquidity'] = matched_liquidity['matched_liquidity']\n",
    "    \n",
    "    # Save the full dataset with matched liquidity identified\n",
    "    now = datetime.datetime.now().strftime('%Y_%m_%d_%I%M%p')\n",
    "    all_games_df.to_csv(f'all_games_orderbook_with_matches_{now}.csv', index=False)\n",
    "    \n",
    "    # Dictionary to store all analyses\n",
    "    all_analyses = {}\n",
    "    \n",
    "    # Process each game individually\n",
    "    for game_id, game_info in all_games_info.items():\n",
    "        # Get game data (full data, not filtered)\n",
    "        game_df = all_games_df[all_games_df['GameID'] == game_id]\n",
    "        \n",
    "        # Calculate matched liquidity percentage\n",
    "        matched_percentage = (game_df['matched_liquidity'].sum() / len(game_df)) * 100 if not game_df.empty else 0\n",
    "        \n",
    "        # Split by market type\n",
    "        ml_df = game_df[game_df['Market'] == 'Moneyline']\n",
    "        spread_df = game_df[game_df['Market'] == 'Spread']\n",
    "        \n",
    "        # Analyze each market using full data\n",
    "        ml_analysis = process_moneyline(ml_df)\n",
    "        spread_analysis = process_spread(spread_df)\n",
    "        \n",
    "        # Combine analyses\n",
    "        game_analysis = {\n",
    "            'game_info': game_info,\n",
    "            'moneyline': ml_analysis,\n",
    "            'spread': spread_analysis,\n",
    "            'matched_liquidity_percentage': matched_percentage,\n",
    "            'matched_liquidity_count': game_df['matched_liquidity'].sum()\n",
    "        }\n",
    "        \n",
    "        # Detect sharp signals\n",
    "        game_analysis['sharp_signals'] = detect_sharp_signals(ml_analysis, spread_analysis)\n",
    "        game_analysis['signal_count'] = len(game_analysis['sharp_signals'])\n",
    "\n",
    "\n",
    "        # In analyze_all_games function\n",
    "        game_analysis['unmatched_liquidity'] = analyze_unmatched_liquidity(game_analysis, game_df)\n",
    "        game_analysis['top_book_imbalance'] = detect_top_book_imbalance(game_analysis, game_df)\n",
    "        # Store analysis\n",
    "        all_analyses[game_id] = game_analysis\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{game_info['event_name']} ({game_info['away_team']} @ {game_info['home_team']})\")\n",
    "        print(\"-------------------------------------------\")\n",
    "        #print_analysis_results(game_analysis)\n",
    "        display_dashboard(all_analyses) \n",
    "        \n",
    "    \n",
    "    return all_analyses, all_games_df\n",
    "\n",
    "\n",
    "def print_analysis_results(analysis):\n",
    "    \"\"\"Print the analysis results in a readable format with highlighted unmatched liquidity\"\"\"\n",
    "    game_info = analysis['game_info']\n",
    "    ml = analysis['moneyline']\n",
    "    spread = analysis['spread']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GAME: {game_info['event_name']}\")\n",
    "    print(f\"Time: {game_info['start_time']}\")\n",
    "    print(f\"{game_info['away_team']} @ {game_info['home_team']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Print moneyline information\n",
    "    print(\"\\n MONEYLINE ANALYSIS:\")\n",
    "    print(f\"Favorite: {ml['favorite_team']} ({ml['favorite_side']})\")\n",
    "    print(f\"Underdog: {ml['underdog_team']} ({ml['underdog_side']})\")\n",
    "    \n",
    "    if ml['has_significant_data']:\n",
    "        if 'favorite_filtered_odds_list' in ml:\n",
    "            print(f\"Favorite odds list: {', '.join(map(str, ml['favorite_filtered_odds_list']))}\")\n",
    "        if 'underdog_filtered_odds_list' in ml:\n",
    "            print(f\"Underdog odds list: {', '.join(map(str, ml['underdog_filtered_odds_list']))}\")\n",
    "        \n",
    "        print(f\"Imbalance ratio: {ml['imbalance']:.2f}\")\n",
    "        print(f\"{ml['favorite_team']} Sum Untaken: ${ml['favorite_all_untaken_sum']:.2f}\")\n",
    "        print(f\"{ml['favorite_team']} Bet Amount: ${ml['favorite_all_bet_amount']:.2f}\")\n",
    "        print(f\"{ml['underdog_team']} Sum Untaken: ${ml['underdog_all_untaken_sum']:.2f}\")\n",
    "        print(f\"{ml['underdog_team']} Bet Amount: ${ml['underdog_all_bet_amount']:.2f}\")\n",
    "    else:\n",
    "        print(\"Insufficient significant data for deeper analysis\")\n",
    "    \n",
    "    # Print spread information\n",
    "    print(\"\\n SPREAD ANALYSIS:\")\n",
    "    print(f\"Main spread: {spread['main_spread']}\")\n",
    "    print(f\"Favorite: {spread['favorite_team']} ({spread['favorite_side']})\")\n",
    "    print(f\"Underdog: {spread['underdog_team']} ({spread['underdog_side']})\")\n",
    "    \n",
    "    if spread['has_significant_data']:\n",
    "        if 'favorite_filtered_odds_list' in spread:\n",
    "            print(f\"Favorite odds list: {', '.join(map(str, spread['favorite_filtered_odds_list']))}\")\n",
    "        if 'underdog_filtered_odds_list' in spread:\n",
    "            print(f\"Underdog odds list: {', '.join(map(str, spread['underdog_filtered_odds_list']))}\")\n",
    "        \n",
    "        print(f\"Imbalance ratio: {spread['imbalance']:.2f}\")\n",
    "        print(f\"{spread['favorite_team']} Sum Untaken: ${spread['favorite_all_untaken']:.2f}\")\n",
    "        print(f\"{spread['favorite_team']} Bet Amount: ${spread['favorite_all_bet']:.2f}\")\n",
    "        print(f\"{spread['underdog_team']} Sum Untaken: ${spread['underdog_all_untaken']:.2f}\")\n",
    "        print(f\"{spread['underdog_team']} Bet Amount: ${spread['underdog_all_bet']:.2f}\")\n",
    "    else:\n",
    "        print(\"Insufficient significant data for deeper analysis\")\n",
    "    \n",
    "    # Print matched liquidity info\n",
    "    print(f\"\\nMatched liquidity: {analysis['matched_liquidity_percentage']:.1f}% ({analysis['matched_liquidity_count']} bets)\")\n",
    "    \n",
    "    # HIGHLIGHT UNMATCHED LIQUIDITY - Make this section stand out\n",
    "    if 'unmatched_liquidity' in analysis:\n",
    "        unmatched = analysis['unmatched_liquidity']\n",
    "        if unmatched['total_signals'] > 0:\n",
    "            print(\"\\n\" + \"!\"*60)\n",
    "            print(\" SIGNIFICANT UNMATCHED LIQUIDITY DETECTED \".center(60))\n",
    "            print(\"!\"*60)\n",
    "            \n",
    "            if unmatched['moneyline_signals']:\n",
    "                print(\"\\n MONEYLINE UNMATCHED LIQUIDITY:\")\n",
    "                for signal in unmatched['moneyline_signals']:\n",
    "                    print(f\"   {signal['team']} ({signal['side']}): ${signal['untaken_amount']:.2f} untaken\")\n",
    "                    if 'price_breakdown' in signal:\n",
    "                        for price in signal['price_breakdown']:\n",
    "                            print(f\"     ${price['amount']:.2f} at {price['price']}\")\n",
    "                    else:\n",
    "                        print(f\"     Top competitive prices: {', '.join(map(str, signal['competitive_prices']))}\")\n",
    "                    print(f\"     Significance: {signal['significance']}\")\n",
    "            \n",
    "            if unmatched['spread_signals']:\n",
    "                print(\"\\n SPREAD UNMATCHED LIQUIDITY:\")\n",
    "                for signal in unmatched['spread_signals']:\n",
    "                    print(f\"   {signal['team']} ({signal['side']}): ${signal['untaken_amount']:.2f} untaken at {signal['spread']}\")\n",
    "                    if 'price_breakdown' in signal:\n",
    "                        for price in signal['price_breakdown']:\n",
    "                            print(f\"     ${price['amount']:.2f} at {price['price']}\")\n",
    "                    else:\n",
    "                        print(f\"     Top competitive prices: {', '.join(map(str, signal['competitive_prices']))}\")\n",
    "                    print(f\"     Significance: {signal['significance']}\")\n",
    "    \n",
    "    # Print sharp signals\n",
    "    if analysis['signal_count'] > 0:\n",
    "        print(\"\\n\" + \"*\"*60)\n",
    "        print(\" SHARP SIGNALS DETECTED \".center(60))\n",
    "        print(\"*\"*60)\n",
    "        for signal in analysis['sharp_signals']:\n",
    "            print(f\"   {signal['market']}: Sharp on {signal['signal']} ({signal['strength']})\")\n",
    "            if 'line' in signal:\n",
    "                print(f\"     Line: {signal['line']}\")\n",
    "            print(f\"     Reason: {signal['reason']}\")\n",
    "    else:\n",
    "        print(\"\\n No strong sharp money signals detected\")\n",
    "    if 'top_book_imbalance' in analysis:\n",
    "        imbalance = analysis['top_book_imbalance']\n",
    "        print(\"\\n TOP OF BOOK SUMMARY\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Show moneyline summary if data exists\n",
    "    if imbalance['moneyline_summary']['has_data']:\n",
    "        ml_summary = imbalance['moneyline_summary']\n",
    "        print(f\"\\n MONEYLINE TOP PRICES:\")\n",
    "        \n",
    "        print(f\"  {ml_summary['favorite_team']} (Favorite):\")\n",
    "        for price_data in ml_summary['favorite_breakdown']:\n",
    "            print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "        \n",
    "        print(f\"  {ml_summary['underdog_team']} (Underdog):\")\n",
    "        for price_data in ml_summary['underdog_breakdown']:\n",
    "            print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "        \n",
    "        # Calculate and show ratio\n",
    "        ratio = 0\n",
    "        if ml_summary['favorite_top_volume'] > 0 and ml_summary['underdog_top_volume'] > 0:\n",
    "            if ml_summary['favorite_top_volume'] > ml_summary['underdog_top_volume']:\n",
    "                ratio = ml_summary['favorite_top_volume'] / ml_summary['underdog_top_volume']\n",
    "                larger_side = ml_summary['favorite_team']\n",
    "            else:\n",
    "                ratio = ml_summary['underdog_top_volume'] / ml_summary['favorite_top_volume']\n",
    "                larger_side = ml_summary['underdog_team']\n",
    "            print(f\"  Volume ratio: {ratio:.2f}x higher for {larger_side}\")\n",
    "    \n",
    "    # Show spread summary if data exists\n",
    "    if imbalance['spread_summary']['has_data']:\n",
    "        spread_summary = imbalance['spread_summary']\n",
    "        print(f\"\\n SPREAD ({spread_summary['main_spread']}) TOP PRICES:\")\n",
    "        \n",
    "        print(f\"  {spread_summary['favorite_team']} (Favorite):\")\n",
    "        for price_data in spread_summary['favorite_breakdown']:\n",
    "            print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "        \n",
    "        print(f\"  {spread_summary['underdog_team']} (Underdog):\")\n",
    "        for price_data in spread_summary['underdog_breakdown']:\n",
    "            print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "        \n",
    "        # Calculate and show ratio\n",
    "        ratio = 0\n",
    "        if spread_summary['favorite_top_volume'] > 0 and spread_summary['underdog_top_volume'] > 0:\n",
    "            if spread_summary['favorite_top_volume'] > spread_summary['underdog_top_volume']:\n",
    "                ratio = spread_summary['favorite_top_volume'] / spread_summary['underdog_top_volume']\n",
    "                larger_side = spread_summary['favorite_team']\n",
    "            else:\n",
    "                ratio = spread_summary['underdog_top_volume'] / spread_summary['favorite_top_volume']\n",
    "                larger_side = spread_summary['underdog_team']\n",
    "            print(f\"  Volume ratio: {ratio:.2f}x higher for {larger_side}\")\n",
    "    if imbalance['total_signals'] > 0:\n",
    "        print(\"\\n\" + \">\"*60)\n",
    "        print(\" TOP OF BOOK IMBALANCE DETECTED \".center(60))\n",
    "        print(\"<\"*60)\n",
    "        \n",
    "        if imbalance['moneyline_signals']:\n",
    "            for signal in imbalance['moneyline_signals']:\n",
    "                print(f\"\\n MONEYLINE IMBALANCE - Signal on {signal['signal']}\")\n",
    "                \n",
    "                print(f\"  Favorite top 3 prices:\")\n",
    "                for price_data in signal['favorite_breakdown']:\n",
    "                    print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "                \n",
    "                print(f\"  Underdog top 3 prices:\")\n",
    "                for price_data in signal['underdog_breakdown']:\n",
    "                    print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "                \n",
    "                print(f\"  Total imbalance: ${signal['favorite_top_volume']:.2f} vs ${signal['underdog_top_volume']:.2f}\")\n",
    "                print(f\"  Ratio: {signal['imbalance_ratio']:.1f}x\")\n",
    "                print(f\"  Significance: {signal['significance']}\")\n",
    "        \n",
    "        if imbalance['spread_signals']:\n",
    "            for signal in imbalance['spread_signals']:\n",
    "                print(f\"\\n SPREAD IMBALANCE - Signal on {signal['signal']}\")\n",
    "                \n",
    "                print(f\"  Favorite top 3 prices:\")\n",
    "                for price_data in signal['favorite_breakdown']:\n",
    "                    print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "                \n",
    "                print(f\"  Underdog top 3 prices:\")\n",
    "                for price_data in signal['underdog_breakdown']:\n",
    "                    print(f\"     ${price_data['volume']:.2f} at {price_data['price']}\")\n",
    "                \n",
    "                print(f\"  Total imbalance: ${signal['favorite_top_volume']:.2f} vs ${signal['underdog_top_volume']:.2f}\")\n",
    "                print(f\"  Ratio: {signal['imbalance_ratio']:.1f}x\")\n",
    "                print(f\"  Significance: {signal['significance']}\")\n",
    "    print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auth_token = grab_auth_token()\n",
    "game_data = scrape_raw_orderbook(auth_token)\n",
    "\n",
    "all_anal, all_df = analyze_all_games(game_data)\n",
    "\n",
    "all_anal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_full_orderbook(game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "def ensure_database_initialized(db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Check if database exists and is properly initialized\"\"\"\n",
    "    if not os.path.exists(db_path):\n",
    "        # Database doesn't exist, create it\n",
    "        initialize_database(db_path)\n",
    "        return\n",
    "    \n",
    "    # Check if tables exist\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Check for key tables\n",
    "    c.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='analysis_results'\")\n",
    "    tables_exist = c.fetchone() is not None\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    if not tables_exist:\n",
    "        # Tables don't exist, initialize database\n",
    "        initialize_database(db_path)\n",
    "\n",
    "def initialize_database(db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Create database tables based on the actual data structure\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Table for raw orderbook snapshots\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS orderbook_snapshots (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        timestamp TEXT NOT NULL,\n",
    "        raw_data TEXT NOT NULL\n",
    "    )''')\n",
    "    \n",
    "    # Table for game metadata\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS games (\n",
    "        game_id TEXT PRIMARY KEY,\n",
    "        event_name TEXT NOT NULL,\n",
    "        league TEXT,\n",
    "        start_time TEXT,\n",
    "        home_team TEXT NOT NULL,\n",
    "        away_team TEXT NOT NULL,\n",
    "        first_seen TEXT NOT NULL,\n",
    "        last_updated TEXT NOT NULL\n",
    "    )''')\n",
    "    \n",
    "    # Table for analysis results with relevant fields\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS analysis_results (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        timestamp TEXT NOT NULL,\n",
    "        game_id TEXT NOT NULL,\n",
    "        \n",
    "        # Key metrics\n",
    "        ml_favorite TEXT,\n",
    "        ml_underdog TEXT,\n",
    "        ml_favorite_best_odds REAL,\n",
    "        ml_underdog_best_odds REAL,\n",
    "        ml_imbalance REAL,\n",
    "        \n",
    "        spread_value REAL,\n",
    "        spread_favorite TEXT,\n",
    "        spread_underdog TEXT,\n",
    "        spread_imbalance REAL,\n",
    "        \n",
    "        matched_liquidity_pct REAL,\n",
    "        matched_liquidity_count INTEGER,\n",
    "        \n",
    "        # Signal indicators\n",
    "        sharp_signal_count INTEGER,\n",
    "        unmatched_signal_count INTEGER,\n",
    "        top_book_signal_count INTEGER,\n",
    "        \n",
    "        # Store full JSON data\n",
    "        analysis_data TEXT NOT NULL,\n",
    "        \n",
    "        FOREIGN KEY (game_id) REFERENCES games(game_id)\n",
    "    )''')\n",
    "    \n",
    "    # Table for individual signals\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS signals (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        analysis_id INTEGER NOT NULL,\n",
    "        game_id TEXT NOT NULL,\n",
    "        timestamp TEXT NOT NULL,\n",
    "        \n",
    "        signal_type TEXT NOT NULL,  # 'sharp', 'unmatched_liquidity', 'top_book_imbalance'\n",
    "        market TEXT NOT NULL,       # 'Moneyline', 'Spread'\n",
    "        team TEXT NOT NULL,\n",
    "        strength TEXT,\n",
    "        imbalance_ratio REAL,\n",
    "        signal_data TEXT NOT NULL,\n",
    "        \n",
    "        FOREIGN KEY (analysis_id) REFERENCES analysis_results(id),\n",
    "        FOREIGN KEY (game_id) REFERENCES games(game_id)\n",
    "    )''')\n",
    "    \n",
    "    # Create indexes\n",
    "    c.execute('CREATE INDEX IF NOT EXISTS idx_games_teams ON games(home_team, away_team)')\n",
    "    c.execute('CREATE INDEX IF NOT EXISTS idx_analysis_timestamp ON analysis_results(timestamp)')\n",
    "    c.execute('CREATE INDEX IF NOT EXISTS idx_analysis_game ON analysis_results(game_id)')\n",
    "    c.execute('CREATE INDEX IF NOT EXISTS idx_signals_game ON signals(game_id)')\n",
    "    c.execute('CREATE INDEX IF NOT EXISTS idx_signals_type ON signals(signal_type)')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Database initialized at {db_path}\")\n",
    "\n",
    "def save_orderbook_snapshot(orderbook_data, db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Save a raw orderbook snapshot and return its ID\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    timestamp = datetime.now().isoformat()\n",
    "    raw_data_json = json.dumps(orderbook_data)\n",
    "    \n",
    "    c.execute('INSERT INTO orderbook_snapshots (timestamp, raw_data) VALUES (?, ?)',\n",
    "              (timestamp, raw_data_json))\n",
    "    \n",
    "    snapshot_id = c.lastrowid\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return snapshot_id, timestamp\n",
    "\n",
    "def save_game_data(games_info, db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Save or update game metadata\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    timestamp = datetime.now().isoformat()\n",
    "    \n",
    "    for game_id, game_info in games_info.items():\n",
    "        # Check if game already exists\n",
    "        c.execute('SELECT game_id FROM games WHERE game_id = ?', (game_id,))\n",
    "        exists = c.fetchone()\n",
    "        \n",
    "        if exists:\n",
    "            # Update existing game\n",
    "            c.execute('''\n",
    "            UPDATE games SET \n",
    "                event_name = ?, \n",
    "                league = ?, \n",
    "                start_time = ?, \n",
    "                home_team = ?, \n",
    "                away_team = ?, \n",
    "                last_updated = ?\n",
    "            WHERE game_id = ?\n",
    "            ''', (\n",
    "                game_info['event_name'],\n",
    "                game_info.get('league', ''),\n",
    "                game_info.get('start_time', ''),\n",
    "                game_info['home_team'],\n",
    "                game_info['away_team'],\n",
    "                timestamp,\n",
    "                game_id\n",
    "            ))\n",
    "        else:\n",
    "            # Insert new game\n",
    "            c.execute('''\n",
    "            INSERT INTO games \n",
    "            (game_id, event_name, league, start_time, home_team, away_team, first_seen, last_updated)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                game_id,\n",
    "                game_info['event_name'],\n",
    "                game_info.get('league', ''),\n",
    "                game_info.get('start_time', ''),\n",
    "                game_info['home_team'],\n",
    "                game_info['away_team'],\n",
    "                timestamp,\n",
    "                timestamp\n",
    "            ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def save_orderbook_details(snapshot_id, timestamp, all_games_df, db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Save detailed orderbook data for each row\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Use a transaction for efficiency\n",
    "    c.execute('BEGIN TRANSACTION')\n",
    "    \n",
    "    try:\n",
    "        for _, row in all_games_df.iterrows():\n",
    "            c.execute('''\n",
    "            INSERT INTO orderbook_details \n",
    "            (snapshot_id, game_id, market, side, team, odds, spread_total, sum_untaken, bet_amount, matched_liquidity, timestamp)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                snapshot_id,\n",
    "                row['GameID'],\n",
    "                row['Market'],\n",
    "                row['Side'],\n",
    "                row['Team'],\n",
    "                float(row['Odds']),\n",
    "                str(row['Spread/Total']),\n",
    "                float(row['Sum Untaken']),\n",
    "                float(row['Bet Amount']),\n",
    "                bool(row['matched_liquidity']),\n",
    "                timestamp\n",
    "            ))\n",
    "        \n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Error saving orderbook details: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def save_analysis_results(timestamp, all_analyses, db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Save analysis results with proper field extraction\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    for game_id, analysis in all_analyses.items():\n",
    "        # Extract key data\n",
    "        ml_data = analysis.get('moneyline', {})\n",
    "        spread_data = analysis.get('spread', {})\n",
    "        \n",
    "        # Insert analysis result\n",
    "        c.execute('''\n",
    "        INSERT INTO analysis_results (\n",
    "            timestamp, game_id, \n",
    "            ml_favorite, ml_underdog, ml_favorite_best_odds, ml_underdog_best_odds, ml_imbalance,\n",
    "            spread_value, spread_favorite, spread_underdog, spread_imbalance,\n",
    "            matched_liquidity_pct, matched_liquidity_count,\n",
    "            sharp_signal_count, unmatched_signal_count, top_book_signal_count,\n",
    "            analysis_data\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            timestamp,\n",
    "            game_id,\n",
    "            ml_data.get('favorite_team'),\n",
    "            ml_data.get('underdog_team'),\n",
    "            ml_data.get('favorite_best_odds'),\n",
    "            ml_data.get('underdog_best_odds'),\n",
    "            ml_data.get('imbalance'),\n",
    "            spread_data.get('main_spread'),\n",
    "            spread_data.get('favorite_team'),\n",
    "            spread_data.get('underdog_team'),\n",
    "            spread_data.get('imbalance'),\n",
    "            analysis.get('matched_liquidity_percentage'),\n",
    "            analysis.get('matched_liquidity_count'),\n",
    "            len(analysis.get('sharp_signals', [])),\n",
    "            analysis.get('unmatched_liquidity', {}).get('total_signals', 0),\n",
    "            analysis.get('top_book_imbalance', {}).get('total_signals', 0),\n",
    "            json.dumps(analysis)\n",
    "        ))\n",
    "        \n",
    "        analysis_id = c.lastrowid\n",
    "        \n",
    "        # Save each individual signal\n",
    "        # Sharp signals\n",
    "        for signal in analysis.get('sharp_signals', []):\n",
    "            c.execute('''\n",
    "            INSERT INTO signals (\n",
    "                analysis_id, game_id, timestamp, signal_type, market, team, \n",
    "                strength, imbalance_ratio, signal_data\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                analysis_id,\n",
    "                game_id,\n",
    "                timestamp,\n",
    "                'sharp',\n",
    "                signal.get('market'),\n",
    "                signal.get('signal'),\n",
    "                signal.get('strength'),\n",
    "                0.0,  # Sharp signals don't have ratio\n",
    "                json.dumps(signal)\n",
    "            ))\n",
    "        \n",
    "        # Unmatched liquidity signals\n",
    "        for market in ['moneyline_signals', 'spread_signals']:\n",
    "            for signal in analysis.get('unmatched_liquidity', {}).get(market, []):\n",
    "                c.execute('''\n",
    "                INSERT INTO signals (\n",
    "                    analysis_id, game_id, timestamp, signal_type, market, team, \n",
    "                    strength, imbalance_ratio, signal_data\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                ''', (\n",
    "                    analysis_id,\n",
    "                    game_id,\n",
    "                    timestamp,\n",
    "                    'unmatched_liquidity',\n",
    "                    'Moneyline' if market == 'moneyline_signals' else 'Spread',\n",
    "                    signal.get('team'),\n",
    "                    signal.get('significance'),\n",
    "                    0.0,  # Unmatched doesn't have ratio\n",
    "                    json.dumps(signal)\n",
    "                ))\n",
    "        \n",
    "        # Top book imbalance signals\n",
    "        for market in ['moneyline_signals', 'spread_signals']:\n",
    "            for signal in analysis.get('top_book_imbalance', {}).get(market, []):\n",
    "                c.execute('''\n",
    "                INSERT INTO signals (\n",
    "                    analysis_id, game_id, timestamp, signal_type, market, team, \n",
    "                    strength, imbalance_ratio, signal_data\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                ''', (\n",
    "                    analysis_id,\n",
    "                    game_id,\n",
    "                    timestamp,\n",
    "                    'top_book_imbalance',\n",
    "                    'Moneyline' if market == 'moneyline_signals' else 'Spread',\n",
    "                    signal.get('signal'),\n",
    "                    signal.get('significance'),\n",
    "                    signal.get('imbalance_ratio', 0.0),\n",
    "                    json.dumps(signal)\n",
    "                ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_recent_signals(hours=24, signal_type=None, market=None, db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Get recent signals of specified type and market\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    query = '''\n",
    "    SELECT g.event_name, g.home_team, g.away_team, g.start_time,\n",
    "           s.timestamp, s.signal_type, s.market, s.team, s.strength, s.imbalance_ratio\n",
    "    FROM signals s\n",
    "    JOIN games g ON s.game_id = g.game_id\n",
    "    WHERE s.timestamp > datetime('now', ?)\n",
    "    '''\n",
    "    params = [f'-{hours} hours']\n",
    "    \n",
    "    if signal_type:\n",
    "        query += ' AND s.signal_type = ?'\n",
    "        params.append(signal_type)\n",
    "    \n",
    "    if market:\n",
    "        query += ' AND s.market = ?'\n",
    "        params.append(market)\n",
    "    \n",
    "    query += ' ORDER BY s.timestamp DESC'\n",
    "    \n",
    "    c.execute(query, params)\n",
    "    results = [dict(row) for row in c.fetchall()]\n",
    "    conn.close()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_dashboard(analyze_func, interval_seconds=300):\n",
    "    \"\"\"Run a live updating dashboard\"\"\"\n",
    "    with console.screen() as screen:\n",
    "        while True:\n",
    "            try:\n",
    "                # Run analysis\n",
    "                analyses, _ = analyze_func()\n",
    "                \n",
    "                # Update dashboard\n",
    "                dashboard = create_dashboard(analyses)\n",
    "                screen.update(dashboard)\n",
    "                \n",
    "                # Wait for next update\n",
    "                time.sleep(interval_seconds)\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                console.print(f\"[bold red]Error: {str(e)}[/bold red]\")\n",
    "                time.sleep(30)  # Wait a bit before retrying\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_games(orderbook_data, db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Analyze all games in the orderbook and detect sharp signals\"\"\"\n",
    "    # Process the full orderbook\n",
    "    ensure_database_initialized(db_path)\n",
    "    snapshot_id, timestamp = save_orderbook_snapshot(orderbook_data, db_path)\n",
    "\n",
    "    all_games_df, all_games_info = process_full_orderbook(orderbook_data)\n",
    "    save_game_data(all_games_info, db_path)\n",
    "    # Add a column for matched liquidity to the full dataset\n",
    "    all_games_df['matched_liquidity'] = False\n",
    "\n",
    "    #For each game, identify matched liquidity for each bet type\n",
    "    for game_id in all_games_df['GameID'].unique():\n",
    "        game_df = all_games_df[all_games_df['GameID'] == game_id]\n",
    "        matched_liquidity = identify_matched_liquidity(game_df, threshold=50)\n",
    "        all_games_df.loc[all_games_df['GameID'] == game_id, 'matched_liquidity'] = matched_liquidity['matched_liquidity']\n",
    "\n",
    "\n",
    "\n",
    "    save_orderbook_details(snapshot_id, timestamp, all_games_df, db_path)\n",
    "    # Save the full dataset with matched liquidity identified\n",
    "    now = datetime.datetime.now().strftime('%Y_%m_%d_%I%M%p')\n",
    "    all_games_df.to_csv(f'all_games_orderbook_with_matches_{now}.csv', index=False)\n",
    "    \n",
    "    # Dictionary to store all analyses\n",
    "    all_analyses = {}\n",
    "    \n",
    "    # Process each game individually\n",
    "    for game_id, game_info in all_games_info.items():\n",
    "        # Get game data (full data, not filtered)\n",
    "        game_df = all_games_df[all_games_df['GameID'] == game_id]\n",
    "        \n",
    "        # Calculate matched liquidity percentage\n",
    "        matched_percentage = (game_df['matched_liquidity'].sum() / len(game_df)) * 100 if not game_df.empty else 0\n",
    "        \n",
    "        # Split by market type\n",
    "        ml_df = game_df[game_df['Market'] == 'Moneyline']\n",
    "        spread_df = game_df[game_df['Market'] == 'Spread']\n",
    "        \n",
    "        # Analyze each market using full data\n",
    "        ml_analysis = process_moneyline(ml_df)\n",
    "        spread_analysis = process_spread(spread_df)\n",
    "        \n",
    "        # Combine analyses\n",
    "        game_analysis = {\n",
    "            'game_info': game_info,\n",
    "            'moneyline': ml_analysis,\n",
    "            'spread': spread_analysis,\n",
    "            'matched_liquidity_percentage': matched_percentage,\n",
    "            'matched_liquidity_count': game_df['matched_liquidity'].sum()\n",
    "        }\n",
    "        \n",
    "        # Detect sharp signals\n",
    "        game_analysis['sharp_signals'] = detect_sharp_signals(ml_analysis, spread_analysis)\n",
    "        game_analysis['signal_count'] = len(game_analysis['sharp_signals'])\n",
    "\n",
    "\n",
    "        # In analyze_all_games function\n",
    "        game_analysis['unmatched_liquidity'] = analyze_unmatched_liquidity(game_analysis, game_df)\n",
    "        game_analysis['top_book_imbalance'] = detect_top_book_imbalance(game_analysis, game_df)\n",
    "        # Store analysis\n",
    "        all_analyses[game_id] = game_analysis\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{game_info['event_name']} ({game_info['away_team']} @ {game_info['home_team']})\")\n",
    "        print(\"-------------------------------------------\")\n",
    "        #print_analysis_results(game_analysis)\n",
    "        display_dashboard(all_analyses) \n",
    "        \n",
    "    \n",
    "    return all_analyses, all_games_df\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def continuous_monitoring(interval_minutes=5, max_hours=24, db_path='orderbook_analyzer.db'):\n",
    "    \"\"\"Continuously monitor the orderbook at specified intervals\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    end_time = start_time + timedelta(hours=max_hours)\n",
    "    \n",
    "    print(f\"Starting continuous monitoring at {start_time}\")\n",
    "    print(f\"Will run until {end_time}\")\n",
    "    print(f\"Data will be saved to {db_path}\")\n",
    "    \n",
    "    while datetime.now() < end_time:\n",
    "        try:\n",
    "            # Get current time for logging\n",
    "            current_time = datetime.now()\n",
    "            print(f\"\\n--- Scraping orderbook at {current_time} ---\")\n",
    "            \n",
    "            # Get auth token and scrape data\n",
    "            auth_token = grab_auth_token()\n",
    "            orderbook_data = scrape_raw_orderbook(auth_token)\n",
    "            \n",
    "            # Analyze the data and save to database\n",
    "            analyses, _ = analyze_all_games(orderbook_data, db_path)\n",
    "            \n",
    "            # Check for signals\n",
    "            signal_count = 0\n",
    "            for game_id, analysis in analyses.items():\n",
    "                total_signals = (\n",
    "                    len(analysis.get('sharp_signals', [])) + \n",
    "                    analysis.get('unmatched_liquidity', {}).get('total_signals', 0) + \n",
    "                    analysis.get('top_book_imbalance', {}).get('total_signals', 0)\n",
    "                )\n",
    "                \n",
    "                if total_signals > 0:\n",
    "                    signal_count += 1\n",
    "                    print(f\"*** SIGNALS DETECTED for {analysis['game_info']['event_name']} ***\")\n",
    "            \n",
    "            print(f\"Completed analysis: {len(analyses)} games, {signal_count} with signals\")\n",
    "            print(f\"All data saved to {db_path}\")\n",
    "            \n",
    "            # Wait for the next interval\n",
    "            next_check = datetime.now() + timedelta(minutes=interval_minutes)\n",
    "            print(f\"Next check scheduled for {next_check}\")\n",
    "            \n",
    "            sleep_time = interval_minutes * 60\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in monitoring loop: {str(e)}\")\n",
    "            print(\"Waiting 2 minutes before retrying...\")\n",
    "            time.sleep(120)\n",
    "    \n",
    "    print(f\"Monitoring complete. Ran from {start_time} to {datetime.now()}\")\n",
    "    print(f\"All data saved to {db_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    db_path = 'orderbook_analyzer.db'\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ORDERBOOK ANALYZER\".center(60))\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n1. Run one-time analysis\")\n",
    "    print(\"2. Start continuous monitoring\")\n",
    "    print(\"3. View recent signals from database\")\n",
    "    print(\"4. Exit\")\n",
    "    \n",
    "    choice = input(\"\\nEnter your choice (1-4): \")\n",
    "    \n",
    "    if choice == '1':\n",
    "        print(\"\\nRunning one-time analysis...\")\n",
    "        auth_token = grab_auth_token()\n",
    "        orderbook_data = scrape_raw_orderbook(auth_token)\n",
    "        analyses, _ = analyze_all_games(orderbook_data, db_path)\n",
    "        input(\"\\nPress Enter to continue...\")\n",
    "        main()\n",
    "        \n",
    "    elif choice == '2':\n",
    "        print(\"\\nStarting continuous monitoring...\")\n",
    "        interval = int(input(\"Enter check interval in minutes (default: 5): \") or \"5\")\n",
    "        duration = int(input(\"Enter monitoring duration in hours (default: 24): \") or \"24\")\n",
    "        continuous_monitoring(interval_minutes=interval, max_hours=duration, db_path=db_path)\n",
    "        main()\n",
    "        \n",
    "    elif choice == '3':\n",
    "        print(\"\\nViewing recent signals...\")\n",
    "        hours = int(input(\"How many hours back to look (default: 24): \") or \"24\")\n",
    "        signals = get_recent_signals(hours=hours, db_path=db_path)\n",
    "        \n",
    "        if signals:\n",
    "            signal_table = Table(title=f\"Recent Signals (Last {hours} hours)\")\n",
    "            signal_table.add_column(\"Game\", style=\"cyan\")\n",
    "            signal_table.add_column(\"Type\", style=\"yellow\")\n",
    "            signal_table.add_column(\"Market\", style=\"magenta\")\n",
    "            signal_table.add_column(\"Team\", style=\"green\")\n",
    "            signal_table.add_column(\"Strength\", style=\"blue\")\n",
    "            signal_table.add_column(\"Time\", style=\"dim\")\n",
    "            \n",
    "            for signal in signals:\n",
    "                signal_table.add_row(\n",
    "                    f\"{signal['away_team']} @ {signal['home_team']}\",\n",
    "                    signal['signal_type'],\n",
    "                    signal['market'],\n",
    "                    signal['team'],\n",
    "                    signal['strength'],\n",
    "                    signal['timestamp'].split('T')[1].split('.')[0]  # Format time\n",
    "                )\n",
    "            \n",
    "            console.print(signal_table)\n",
    "        else:\n",
    "            print(\"No signals found in the specified time period.\")\n",
    "        \n",
    "        input(\"\\nPress Enter to continue...\")\n",
    "        main()\n",
    "        \n",
    "    elif choice == '4':\n",
    "        print(\"\\nExiting...\")\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nInvalid choice. Please try again.\")\n",
    "        main()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4casters-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
